# Image Augmentation

Following are the techniques used to avoid **overfitting**.

* DropOut
* BatchNormalization
* L1/L2 Regularization
* Layer Normalization?

But, the above *will fail* if the there is no sufficient data to train. The different **data augmentation** strategies come to rescue.

###  What is Augmentation?

Performing the one or more of the following operation: Scale, Rotate, Transaltion, Blurring, Mirroring, Color Shifting etc. results in new image, would help to train the Deep Learning Model.



### What are the different Augmentation options/libraries available?

* [ImgAug](<https://github.com/aleju/imgaug>)

* Elastic Distortion 2003

* Spatial DropOut 2014 - Not used much

* Batch Normalization - 2015

* Label Smoothing - Year 2016

* [CutOut  - Year 2017](<https://github.com/yu4u/cutout-random-erasing>)

* Smart Augmentation - Mar 2017

* Mixup - April 2018

* Sample Pairing - May 2018

* Using Reinforcement Learning - Auto Augment - May 2018 - Expensive

* RICAP - Nov 2018

* Data Augmentation Policies by Bayesian Optimisation - May 2019

* Population based Augmentation - May 2019

* Patch Gaussian Augmentation - June 2019

  

