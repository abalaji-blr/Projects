{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOFP3TxYOJlg2J5ieuYF5B1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Named Entity Recognition (NER)** Using SpaCy\n","\n","The idea is to extract the person, values, location and so on.\n","\n"],"metadata":{"id":"hG0RKnJLEX-u"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"gWb48PTIEQC1","executionInfo":{"status":"ok","timestamp":1681195775603,"user_tz":-330,"elapsed":10348,"user":{"displayName":"Balaji Anandan","userId":"04377515888334806424"}}},"outputs":[],"source":["import spacy"]},{"cell_type":"code","source":["!python -m spacy download en_core_web_md"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rf6igNqKGRCT","executionInfo":{"status":"ok","timestamp":1681196155225,"user_tz":-330,"elapsed":15672,"user":{"displayName":"Balaji Anandan","userId":"04377515888334806424"}},"outputId":"d017f923-c5a2-44df-e771-a234d646aa6c"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-04-11 06:55:47.666532: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting en-core-web-md==3.5.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.5.0/en_core_web_md-3.5.0-py3-none-any.whl (42.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from en-core-web-md==3.5.0) (3.5.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.10.7)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.10.1)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (23.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.8)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.9)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (67.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.1.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.9)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.65.0)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.1.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.27.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.8)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.12)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.7)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.3.0)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.4.6)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.4)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.22.4)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (6.3.0)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2022.12.7)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.9)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.0.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.1.2)\n","Installing collected packages: en-core-web-md\n","Successfully installed en-core-web-md-3.5.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_md')\n"]}]},{"cell_type":"code","source":["# we need to download the models from SpaCy\n","## model names: Lang_Type_Genre_Size \n","#\n","nlp = spacy.load('en_core_web_md')"],"metadata":{"id":"nd_B35nBE4ot","executionInfo":{"status":"ok","timestamp":1681196161632,"user_tz":-330,"elapsed":1388,"user":{"displayName":"Balaji Anandan","userId":"04377515888334806424"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["txt = (\"Tesla (TSLA) cut prices on its full U.S. lineup for the third time in 2023, \"\n","       \"slashing up to $5,000 off of its EVs. Tom Narayan, RBC Capital Markets Lead Equity Analyst\"\n","       \" for Global Autos joined Yahoo Finance to discuss the cuts.\"\n","      \"Narayan explained that Tesla’s lower costs makes it easier for the company to cut\"\n","      \"prices without sacrificing profits. “I do think that this strategy of cutting prices gonna lead\"\n","      \"to a higher sales, and fortunately for them, they do have some unique characteristics that make it so\"\n","       \"they don't have to sacrifice too much on profitability,” he told Yahoo Finance.\"\n","       )"],"metadata":{"id":"hZIiNy9AFVrl","executionInfo":{"status":"ok","timestamp":1681196511296,"user_tz":-330,"elapsed":466,"user":{"displayName":"Balaji Anandan","userId":"04377515888334806424"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["nlp(txt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U09rIvYXHuqB","executionInfo":{"status":"ok","timestamp":1681196518345,"user_tz":-330,"elapsed":5,"user":{"displayName":"Balaji Anandan","userId":"04377515888334806424"}},"outputId":"96828d2b-007f-46c0-e748-d96cbbe2abdd"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Tesla (TSLA) cut prices on its full U.S. lineup for the third time in 2023, slashing up to $5,000 off of its EVs. Tom Narayan, RBC Capital Markets Lead Equity Analyst for Global Autos joined Yahoo Finance to discuss the cuts.Narayan explained that Tesla’s lower costs makes it easier for the company to cutprices without sacrificing profits. “I do think that this strategy of cutting prices gonna leadto a higher sales, and fortunately for them, they do have some unique characteristics that make it sothey don't have to sacrifice too much on profitability,” he told Yahoo Finance."]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["doc = nlp(txt)"],"metadata":{"id":"2ZhrxwQyHwLl","executionInfo":{"status":"ok","timestamp":1681196567512,"user_tz":-330,"elapsed":2,"user":{"displayName":"Balaji Anandan","userId":"04377515888334806424"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["type(doc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"87YXpTeGH8WW","executionInfo":{"status":"ok","timestamp":1681196571766,"user_tz":-330,"elapsed":3,"user":{"displayName":"Balaji Anandan","userId":"04377515888334806424"}},"outputId":"15148ea0-e552-4dc8-f6a8-0c2b8dc448e5"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["spacy.tokens.doc.Doc"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["from spacy import displacy"],"metadata":{"id":"jlOVRsHPH9Wu","executionInfo":{"status":"ok","timestamp":1681196631508,"user_tz":-330,"elapsed":2,"user":{"displayName":"Balaji Anandan","userId":"04377515888334806424"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["displacy.render(doc, style = 'ent', jupyter = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":157},"id":"XS1XtYH9IJvn","executionInfo":{"status":"ok","timestamp":1681196834006,"user_tz":-330,"elapsed":6,"user":{"displayName":"Balaji Anandan","userId":"04377515888334806424"}},"outputId":"daaca934-1667-4720-c047-23f40ea51c69"},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Tesla\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n"," (TSLA) cut prices on its full \n","<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    U.S.\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n","</mark>\n"," lineup for the \n","<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    third\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n","</mark>\n"," time in \n","<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    2023\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n","</mark>\n",", slashing \n","<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    up to $5,000\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n","</mark>\n"," off of its EVs. \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Tom Narayan\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n",", \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    RBC Capital Markets Lead Equity Analyst\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n"," for \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Global Autos\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n"," joined \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Yahoo Finance\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n"," to discuss the cuts.\n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Narayan\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n"," explained that \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Tesla\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n","’s lower costs makes it easier for the company to cutprices without sacrificing profits. “I do think that this strategy of cutting prices gonna leadto a higher sales, and fortunately for them, they do have some unique characteristics that make it sothey don't have to sacrifice too much on profitability,” he told \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Yahoo Finance\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n",".</div></span>"]},"metadata":{}}]},{"cell_type":"code","source":["spacy.explain('GPE') # geo political entities"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"A7n7qphQIRVQ","executionInfo":{"status":"ok","timestamp":1681196915198,"user_tz":-330,"elapsed":5,"user":{"displayName":"Balaji Anandan","userId":"04377515888334806424"}},"outputId":"44501e7c-c087-4272-a1bc-e25198f474e1"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Countries, cities, states'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["spacy.explain('ORG') # organization"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"l5I-_jMVJRR-","executionInfo":{"status":"ok","timestamp":1681197030257,"user_tz":-330,"elapsed":455,"user":{"displayName":"Balaji Anandan","userId":"04377515888334806424"}},"outputId":"dcced1dd-f769-46e2-8a18-a9018a80e4e8"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Companies, agencies, institutions, etc.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["doc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hydp37seJUXG","executionInfo":{"status":"ok","timestamp":1681197102611,"user_tz":-330,"elapsed":4,"user":{"displayName":"Balaji Anandan","userId":"04377515888334806424"}},"outputId":"535941d6-d488-48fe-8908-b2905766e10b"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Tesla (TSLA) cut prices on its full U.S. lineup for the third time in 2023, slashing up to $5,000 off of its EVs. Tom Narayan, RBC Capital Markets Lead Equity Analyst for Global Autos joined Yahoo Finance to discuss the cuts.Narayan explained that Tesla’s lower costs makes it easier for the company to cutprices without sacrificing profits. “I do think that this strategy of cutting prices gonna leadto a higher sales, and fortunately for them, they do have some unique characteristics that make it sothey don't have to sacrifice too much on profitability,” he told Yahoo Finance."]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["help(doc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v65kMRc2J-9z","executionInfo":{"status":"ok","timestamp":1681197145312,"user_tz":-330,"elapsed":7,"user":{"displayName":"Balaji Anandan","userId":"04377515888334806424"}},"outputId":"bfde13c9-de38-477c-a16d-4bda7a901258"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Help on Doc object:\n","\n","class Doc(builtins.object)\n"," |  Doc(Vocab vocab, words=None, spaces=None, user_data=None, *, tags=None, pos=None, morphs=None, lemmas=None, heads=None, deps=None, sent_starts=None, ents=None)\n"," |  A sequence of Token objects. Access sentences and named entities, export\n"," |      annotations to numpy arrays, losslessly serialize to compressed binary\n"," |      strings. The `Doc` object holds an array of `TokenC` structs. The\n"," |      Python-level `Token` and `Span` objects are views of this array, i.e.\n"," |      they don't own the data themselves.\n"," |  \n"," |      EXAMPLE:\n"," |          Construction 1\n"," |          >>> doc = nlp(u'Some text')\n"," |  \n"," |          Construction 2\n"," |          >>> from spacy.tokens import Doc\n"," |          >>> doc = Doc(nlp.vocab, words=[\"hello\", \"world\", \"!\"], spaces=[True, False, False])\n"," |  \n"," |      DOCS: https://spacy.io/api/doc\n"," |  \n"," |  Methods defined here:\n"," |  \n"," |  __bytes__(...)\n"," |      Doc.__bytes__(self)\n"," |  \n"," |  __getitem__(...)\n"," |      Get a `Token` or `Span` object.\n"," |      \n"," |      i (int or tuple) The index of the token, or the slice of the document\n"," |          to get.\n"," |      RETURNS (Token or Span): The token at `doc[i]]`, or the span at\n"," |          `doc[start : end]`.\n"," |      \n"," |      EXAMPLE:\n"," |          >>> doc[i]\n"," |          Get the `Token` object at position `i`, where `i` is an integer.\n"," |          Negative indexing is supported, and follows the usual Python\n"," |          semantics, i.e. `doc[-2]` is `doc[len(doc) - 2]`.\n"," |      \n"," |          >>> doc[start : end]]\n"," |          Get a `Span` object, starting at position `start` and ending at\n"," |          position `end`, where `start` and `end` are token indices. For\n"," |          instance, `doc[2:5]` produces a span consisting of tokens 2, 3 and\n"," |          4. Stepped slices (e.g. `doc[start : end : step]`) are not\n"," |          supported, as `Span` objects must be contiguous (cannot have gaps).\n"," |          You can use negative indices and open-ended ranges, which have\n"," |          their normal Python semantics.\n"," |      \n"," |      DOCS: https://spacy.io/api/doc#getitem\n"," |  \n"," |  __init__(...)\n"," |      Create a Doc object.\n"," |      \n"," |      vocab (Vocab): A vocabulary object, which must match any models you\n"," |          want to use (e.g. tokenizer, parser, entity recognizer).\n"," |      words (Optional[List[Union[str, int]]]): A list of unicode strings or\n"," |          hash values to add to the document as words. If `None`, defaults to\n"," |          empty list.\n"," |      spaces (Optional[List[bool]]): A list of boolean values, of the same\n"," |          length as `words`. `True` means that the word is followed by a space,\n"," |          `False` means it is not. If `None`, defaults to `[True]*len(words)`\n"," |      user_data (dict or None): Optional extra data to attach to the Doc.\n"," |      tags (Optional[List[str]]): A list of unicode strings, of the same\n"," |          length as words, to assign as token.tag. Defaults to None.\n"," |      pos (Optional[List[str]]): A list of unicode strings, of the same\n"," |          length as words, to assign as token.pos. Defaults to None.\n"," |      morphs (Optional[List[str]]): A list of unicode strings, of the same\n"," |          length as words, to assign as token.morph. Defaults to None.\n"," |      lemmas (Optional[List[str]]): A list of unicode strings, of the same\n"," |          length as words, to assign as token.lemma. Defaults to None.\n"," |      heads (Optional[List[int]]): A list of values, of the same length as\n"," |          words, to assign as heads. Head indices are the position of the\n"," |          head in the doc. Defaults to None.\n"," |      deps (Optional[List[str]]): A list of unicode strings, of the same\n"," |          length as words, to assign as token.dep. Defaults to None.\n"," |      sent_starts (Optional[List[Union[bool, int, None]]]): A list of values, \n"," |          of the same length as words, to assign as token.is_sent_start. Will \n"," |          be overridden by heads if heads is provided. Defaults to None.\n"," |      ents (Optional[List[str]]): A list of unicode strings, of the same\n"," |          length as words, as IOB tags to assign as token.ent_iob and\n"," |          token.ent_type. Defaults to None.\n"," |      \n"," |      DOCS: https://spacy.io/api/doc#init\n"," |  \n"," |  __iter__(...)\n"," |      Iterate over `Token`  objects, from which the annotations can be\n"," |      easily accessed. This is the main way of accessing `Token` objects,\n"," |      which are the main way annotations are accessed from Python. If faster-\n"," |      than-Python speeds are required, you can instead access the annotations\n"," |      as a numpy array, or access the underlying C data directly from Cython.\n"," |      \n"," |      DOCS: https://spacy.io/api/doc#iter\n"," |  \n"," |  __len__(...)\n"," |      The number of tokens in the document.\n"," |      \n"," |      RETURNS (int): The number of tokens in the document.\n"," |      \n"," |      DOCS: https://spacy.io/api/doc#len\n"," |  \n"," |  __reduce__ = __reduce_cython__(...)\n"," |      Doc.__reduce_cython__(self)\n"," |  \n"," |  __repr__(self, /)\n"," |      Return repr(self).\n"," |  \n"," |  __setstate__ = __setstate_cython__(...)\n"," |      Doc.__setstate_cython__(self, __pyx_state)\n"," |  \n"," |  __str__(self, /)\n"," |      Return str(self).\n"," |  \n"," |  __unicode__(...)\n"," |      Doc.__unicode__(self)\n"," |  \n"," |  char_span(...)\n"," |      Doc.char_span(self, int start_idx, int end_idx, label=0, kb_id=0, vector=None, alignment_mode='strict', span_id=0)\n"," |      Create a `Span` object from the slice\n"," |              `doc.text[start_idx : end_idx]`. Returns None if no valid `Span` can be\n"," |              created.\n"," |      \n"," |              doc (Doc): The parent document.\n"," |              start_idx (int): The index of the first character of the span.\n"," |              end_idx (int): The index of the first character after the span.\n"," |              label (Union[int, str]): A label to attach to the Span, e.g. for\n"," |                  named entities.\n"," |              kb_id (Union[int, str]):  An ID from a KB to capture the meaning of a\n"," |                  named entity.\n"," |              vector (ndarray[ndim=1, dtype='float32']): A meaning representation of\n"," |                  the span.\n"," |              alignment_mode (str): How character indices are aligned to token\n"," |                  boundaries. Options: \"strict\" (character indices must be aligned\n"," |                  with token boundaries), \"contract\" (span of all tokens completely\n"," |                  within the character span), \"expand\" (span of all tokens at least\n"," |                  partially covered by the character span). Defaults to \"strict\".\n"," |              span_id (Union[int, str]): An identifier to associate with the span.\n"," |              RETURNS (Span): The newly constructed object.\n"," |      \n"," |              DOCS: https://spacy.io/api/doc#char_span\n"," |  \n"," |  copy(...)\n"," |      Doc.copy(self)\n"," |  \n"," |  count_by(...)\n"," |      Doc.count_by(self, attr_id_t attr_id, exclude=None, counts=None)\n"," |      Count the frequencies of a given attribute. Produces a dict of\n"," |              `{attribute (int): count (ints)}` frequencies, keyed by the values of\n"," |              the given attribute ID.\n"," |      \n"," |              attr_id (int): The attribute ID to key the counts.\n"," |              RETURNS (dict): A dictionary mapping attributes to integer counts.\n"," |      \n"," |              DOCS: https://spacy.io/api/doc#count_by\n"," |  \n"," |  extend_tensor(...)\n"," |      Doc.extend_tensor(self, tensor)\n"," |      Concatenate a new tensor onto the doc.tensor object.\n"," |      \n"," |              The doc.tensor attribute holds dense feature vectors\n"," |              computed by the models in the pipeline. Let's say a\n"," |              document with 30 words has a tensor with 128 dimensions\n"," |              per word. doc.tensor.shape will be (30, 128). After\n"," |              calling doc.extend_tensor with an array of shape (30, 64),\n"," |              doc.tensor == (30, 192).\n"," |  \n"," |  from_array(...)\n"," |      Doc.from_array(self, attrs, array)\n"," |      Load attributes from a numpy array. Write to a `Doc` object, from an\n"," |              `(M, N)` array of attributes.\n"," |      \n"," |              attrs (list) A list of attribute ID ints.\n"," |              array (numpy.ndarray[ndim=2, dtype='int32']): The attribute values.\n"," |              RETURNS (Doc): Itself.\n"," |      \n"," |              DOCS: https://spacy.io/api/doc#from_array\n"," |  \n"," |  from_bytes(...)\n"," |      Doc.from_bytes(self, bytes_data, *, exclude=tuple())\n"," |      Deserialize, i.e. import the document contents from a binary string.\n"," |      \n"," |              data (bytes): The string to load from.\n"," |              exclude (list): String names of serialization fields to exclude.\n"," |              RETURNS (Doc): Itself.\n"," |      \n"," |              DOCS: https://spacy.io/api/doc#from_bytes\n"," |  \n"," |  from_dict(...)\n"," |      Doc.from_dict(self, msg, *, exclude=tuple())\n"," |      Deserialize, i.e. import the document contents from a binary string.\n"," |      \n"," |              data (bytes): The string to load from.\n"," |              exclude (list): String names of serialization fields to exclude.\n"," |              RETURNS (Doc): Itself.\n"," |      \n"," |              DOCS: https://spacy.io/api/doc#from_dict\n"," |  \n"," |  from_disk(...)\n"," |      Doc.from_disk(self, path, *, exclude=tuple())\n"," |      Loads state from a directory. Modifies the object in place and\n"," |              returns it.\n"," |      \n"," |              path (str / Path): A path to a directory. Paths may be either\n"," |                  strings or `Path`-like objects.\n"," |              exclude (list): String names of serialization fields to exclude.\n"," |              RETURNS (Doc): The modified `Doc` object.\n"," |      \n"," |              DOCS: https://spacy.io/api/doc#from_disk\n"," |  \n"," |  from_json(...)\n"," |      Doc.from_json(self, doc_json, *, validate=False)\n"," |      Convert a JSON document generated by Doc.to_json() to a Doc.\n"," |      \n"," |              doc_json (Dict): JSON representation of doc object to load.\n"," |              validate (bool): Whether to validate `doc_json` against the expected schema.\n"," |                  Defaults to False.\n"," |              RETURNS (Doc): A doc instance corresponding to the specified JSON representation.\n"," |  \n"," |  get_lca_matrix(...)\n"," |      Doc.get_lca_matrix(self)\n"," |      Calculates a matrix of Lowest Common Ancestors (LCA) for a given\n"," |              `Doc`, where LCA[i, j] is the index of the lowest common ancestor among\n"," |              token i and j.\n"," |      \n"," |              RETURNS (np.array[ndim=2, dtype=numpy.int32]): LCA matrix with shape\n"," |                  (n, n), where n = len(self).\n"," |      \n"," |              DOCS: https://spacy.io/api/doc#get_lca_matrix\n"," |  \n"," |  has_annotation(...)\n"," |      Doc.has_annotation(self, attr, *, require_complete=False)\n"," |      Check whether the doc contains annotation on a token attribute.\n"," |      \n"," |              attr (Union[int, str]): The attribute string name or int ID.\n"," |              require_complete (bool): Whether to check that the attribute is set on\n"," |                  every token in the doc.\n"," |              RETURNS (bool): Whether annotation is present.\n"," |      \n"," |              DOCS: https://spacy.io/api/doc#has_annotation\n"," |  \n"," |  retokenize(...)\n"," |      Doc.retokenize(self)\n"," |      Context manager to handle retokenization of the Doc.\n"," |              Modifications to the Doc's tokenization are stored, and then\n"," |              made all at once when the context manager exits. This is\n"," |              much more efficient, and less error-prone.\n"," |      \n"," |              All views of the Doc (Span and Token) created before the\n"," |              retokenization are invalidated, although they may accidentally\n"," |              continue to work.\n"," |      \n"," |              DOCS: https://spacy.io/api/doc#retokenize\n"," |              USAGE: https://spacy.io/usage/linguistic-features#retokenization\n"," |  \n"," |  set_ents(...)\n"," |      Doc.set_ents(self, entities, *, blocked=None, missing=None, outside=None, default=SetEntsDefault.outside)\n"," |      Set entity annotation.\n"," |      \n"," |              entities (List[Span]): Spans with labels to set as entities.\n"," |              blocked (Optional[List[Span]]): Spans to set as 'blocked' (never an\n"," |                  entity) for spacy's built-in NER component. Other components may\n"," |                  ignore this setting.\n"," |              missing (Optional[List[Span]]): Spans with missing/unknown entity\n"," |                  information.\n"," |              outside (Optional[List[Span]]): Spans outside of entities (O in IOB).\n"," |              default (str): How to set entity annotation for tokens outside of any\n"," |                  provided spans. Options: \"blocked\", \"missing\", \"outside\" and\n"," |                  \"unmodified\" (preserve current state). Defaults to \"outside\".\n"," |  \n"," |  similarity(...)\n"," |      Doc.similarity(self, other)\n"," |      Make a semantic similarity estimate. The default estimate is cosine\n"," |              similarity using an average of word vectors.\n"," |      \n"," |              other (object): The object to compare with. By default, accepts `Doc`,\n"," |                  `Span`, `Token` and `Lexeme` objects.\n"," |              RETURNS (float): A scalar similarity score. Higher is more similar.\n"," |      \n"," |              DOCS: https://spacy.io/api/doc#similarity\n"," |  \n"," |  to_array(...)\n"," |      Doc.to_array(self, py_attr_ids) -> ndarray\n"," |      Export given token attributes to a numpy `ndarray`.\n"," |              If `attr_ids` is a sequence of M attributes, the output array will be\n"," |              of shape `(N, M)`, where N is the length of the `Doc` (in tokens). If\n"," |              `attr_ids` is a single attribute, the output shape will be (N,). You\n"," |              can specify attributes by integer ID (e.g. spacy.attrs.LEMMA) or\n"," |              string name (e.g. 'LEMMA' or 'lemma').\n"," |      \n"," |              py_attr_ids (list[]): A list of attributes (int IDs or string names).\n"," |              RETURNS (numpy.ndarray[long, ndim=2]): A feature matrix, with one row\n"," |                  per word, and one column per attribute indicated in the input\n"," |                  `attr_ids`.\n"," |      \n"," |              EXAMPLE:\n"," |                  >>> from spacy.attrs import LOWER, POS, ENT_TYPE, IS_ALPHA\n"," |                  >>> doc = nlp(text)\n"," |                  >>> # All strings mapped to integers, for easy export to numpy\n"," |                  >>> np_array = doc.to_array([LOWER, POS, ENT_TYPE, IS_ALPHA])\n"," |  \n"," |  to_bytes(...)\n"," |      Doc.to_bytes(self, *, exclude=tuple())\n"," |      Serialize, i.e. export the document contents to a binary string.\n"," |      \n"," |              exclude (list): String names of serialization fields to exclude.\n"," |              RETURNS (bytes): A losslessly serialized copy of the `Doc`, including\n"," |                  all annotations.\n"," |      \n"," |              DOCS: https://spacy.io/api/doc#to_bytes\n"," |  \n"," |  to_dict(...)\n"," |      Doc.to_dict(self, *, exclude=tuple())\n"," |      Export the document contents to a dictionary for serialization.\n"," |      \n"," |              exclude (list): String names of serialization fields to exclude.\n"," |              RETURNS (bytes): A losslessly serialized copy of the `Doc`, including\n"," |                  all annotations.\n"," |      \n"," |              DOCS: https://spacy.io/api/doc#to_bytes\n"," |  \n"," |  to_disk(...)\n"," |      Doc.to_disk(self, path, *, exclude=tuple())\n"," |      Save the current state to a directory.\n"," |      \n"," |              path (str / Path): A path to a directory, which will be created if\n"," |                  it doesn't exist. Paths may be either strings or Path-like objects.\n"," |              exclude (Iterable[str]): String names of serialization fields to exclude.\n"," |      \n"," |              DOCS: https://spacy.io/api/doc#to_disk\n"," |  \n"," |  to_json(...)\n"," |      Doc.to_json(self, underscore=None)\n"," |      Convert a Doc to JSON.\n"," |      \n"," |              underscore (list): Optional list of string names of custom doc._.\n"," |              attributes. Attribute values need to be JSON-serializable. Values will\n"," |              be added to an \"_\" key in the data, e.g. \"_\": {\"foo\": \"bar\"}.\n"," |              RETURNS (dict): The data in JSON format.\n"," |  \n"," |  to_utf8_array(...)\n"," |      Doc.to_utf8_array(self, int nr_char=-1)\n"," |      Encode word strings to utf8, and export to a fixed-width array\n"," |              of characters. Characters are placed into the array in the order:\n"," |                  0, -1, 1, -2, etc\n"," |              For example, if the array is sliced array[:, :8], the array will\n"," |              contain the first 4 characters and last 4 characters of each word ---\n"," |              with the middle characters clipped out. The value 255 is used as a pad\n"," |              value.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Class methods defined here:\n"," |  \n"," |  get_extension(...) from builtins.type\n"," |      Doc.get_extension(type cls, name)\n"," |      Look up a previously registered extension by name.\n"," |      \n"," |              name (str): Name of the extension.\n"," |              RETURNS (tuple): A `(default, method, getter, setter)` tuple.\n"," |      \n"," |              DOCS: https://spacy.io/api/doc#get_extension\n"," |  \n"," |  has_extension(...) from builtins.type\n"," |      Doc.has_extension(type cls, name)\n"," |      Check whether an extension has been registered.\n"," |      \n"," |              name (str): Name of the extension.\n"," |              RETURNS (bool): Whether the extension has been registered.\n"," |      \n"," |              DOCS: https://spacy.io/api/doc#has_extension\n"," |  \n"," |  remove_extension(...) from builtins.type\n"," |      Doc.remove_extension(type cls, name)\n"," |      Remove a previously registered extension.\n"," |      \n"," |              name (str): Name of the extension.\n"," |              RETURNS (tuple): A `(default, method, getter, setter)` tuple of the\n"," |                  removed extension.\n"," |      \n"," |              DOCS: https://spacy.io/api/doc#remove_extension\n"," |  \n"," |  set_extension(...) from builtins.type\n"," |      Doc.set_extension(type cls, name, **kwargs)\n"," |      Define a custom attribute which becomes available as `Doc._`.\n"," |      \n"," |              name (str): Name of the attribute to set.\n"," |              default: Optional default value of the attribute.\n"," |              getter (callable): Optional getter function.\n"," |              setter (callable): Optional setter function.\n"," |              method (callable): Optional method for method extension.\n"," |              force (bool): Force overwriting existing attribute.\n"," |      \n"," |              DOCS: https://spacy.io/api/doc#set_extension\n"," |              USAGE: https://spacy.io/usage/processing-pipelines#custom-components-attributes\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Static methods defined here:\n"," |  \n"," |  __new__(*args, **kwargs) from builtins.type\n"," |      Create and return a new object.  See help(type) for accurate signature.\n"," |  \n"," |  from_docs(...)\n"," |      Doc.from_docs(docs, ensure_whitespace=True, attrs=None, *, exclude=tuple())\n"," |      Concatenate multiple Doc objects to form a new one. Raises an error\n"," |              if the `Doc` objects do not all share the same `Vocab`.\n"," |      \n"," |              docs (list): A list of Doc objects.\n"," |              ensure_whitespace (bool): Insert a space between two adjacent docs\n"," |                  whenever the first doc does not end in whitespace.\n"," |              attrs (list): Optional list of attribute ID ints or attribute name\n"," |                  strings.\n"," |              exclude (Iterable[str]): Doc attributes to exclude. Supported\n"," |                  attributes: `spans`, `tensor`, `user_data`.\n"," |              RETURNS (Doc): A doc that contains the concatenated docs, or None if no\n"," |                  docs were given.\n"," |      \n"," |              DOCS: https://spacy.io/api/doc#from_docs\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data descriptors defined here:\n"," |  \n"," |  cats\n"," |      cats: object\n"," |  \n"," |  doc\n"," |  \n"," |  ents\n"," |      The named entities in the document. Returns a tuple of named entity\n"," |      `Span` objects, if the entity recognizer has been applied.\n"," |      \n"," |      RETURNS (tuple): Entities in the document, one `Span` per entity.\n"," |      \n"," |      DOCS: https://spacy.io/api/doc#ents\n"," |  \n"," |  has_unknown_spaces\n"," |      has_unknown_spaces: 'bool'\n"," |  \n"," |  has_vector\n"," |      A boolean value indicating whether a word vector is associated with\n"," |      the object.\n"," |      \n"," |      RETURNS (bool): Whether a word vector is associated with the object.\n"," |      \n"," |      DOCS: https://spacy.io/api/doc#has_vector\n"," |  \n"," |  is_nered\n"," |  \n"," |  is_parsed\n"," |  \n"," |  is_sentenced\n"," |  \n"," |  is_tagged\n"," |  \n"," |  lang\n"," |      RETURNS (uint64): ID of the language of the doc's vocabulary.\n"," |  \n"," |  lang_\n"," |      RETURNS (str): Language of the doc's vocabulary, e.g. 'en'.\n"," |  \n"," |  mem\n"," |  \n"," |  noun_chunks\n"," |      Iterate over the base noun phrases in the document. Yields base\n"," |      noun-phrase #[code Span] objects, if the language has a noun chunk iterator.\n"," |      Raises a NotImplementedError otherwise.\n"," |      \n"," |      A base noun phrase, or \"NP chunk\", is a noun\n"," |      phrase that does not permit other NPs to be nested within it – so no\n"," |      NP-level coordination, no prepositional phrases, and no relative\n"," |      clauses.\n"," |      \n"," |      YIELDS (Span): Noun chunks in the document.\n"," |      \n"," |      DOCS: https://spacy.io/api/doc#noun_chunks\n"," |  \n"," |  noun_chunks_iterator\n"," |      noun_chunks_iterator: object\n"," |  \n"," |  sentiment\n"," |      sentiment: 'float'\n"," |  \n"," |  sents\n"," |      Iterate over the sentences in the document. Yields sentence `Span`\n"," |      objects. Sentence spans have no label.\n"," |      \n"," |      YIELDS (Span): Sentences in the document.\n"," |      \n"," |      DOCS: https://spacy.io/api/doc#sents\n"," |  \n"," |  spans\n"," |  \n"," |  tensor\n"," |      tensor: object\n"," |  \n"," |  text\n"," |      A unicode representation of the document text.\n"," |      \n"," |      RETURNS (str): The original verbatim text of the document.\n"," |  \n"," |  text_with_ws\n"," |      An alias of `Doc.text`, provided for duck-type compatibility with\n"," |      `Span` and `Token`.\n"," |      \n"," |      RETURNS (str): The original verbatim text of the document.\n"," |  \n"," |  user_data\n"," |      user_data: object\n"," |  \n"," |  user_hooks\n"," |      user_hooks: dict\n"," |  \n"," |  user_span_hooks\n"," |      user_span_hooks: dict\n"," |  \n"," |  user_token_hooks\n"," |      user_token_hooks: dict\n"," |  \n"," |  vector\n"," |      A real-valued meaning representation. Defaults to an average of the\n"," |      token vectors.\n"," |      \n"," |      RETURNS (numpy.ndarray[ndim=1, dtype='float32']): A 1D numpy array\n"," |          representing the document's semantics.\n"," |      \n"," |      DOCS: https://spacy.io/api/doc#vector\n"," |  \n"," |  vector_norm\n"," |      The L2 norm of the document's vector representation.\n"," |      \n"," |      RETURNS (float): The L2 norm of the vector representation.\n"," |      \n"," |      DOCS: https://spacy.io/api/doc#vector_norm\n"," |  \n"," |  vocab\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data and other attributes defined here:\n"," |  \n"," |  __pyx_vtable__ = <capsule object NULL>\n","\n"]}]},{"cell_type":"code","source":["doc.ents # get the list of entities"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xh8GZOK0KJez","executionInfo":{"status":"ok","timestamp":1681197206591,"user_tz":-330,"elapsed":4,"user":{"displayName":"Balaji Anandan","userId":"04377515888334806424"}},"outputId":"f19221bc-a70c-4ad5-bbc2-11c1b4a8ec7b"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(Tesla,\n"," U.S.,\n"," third,\n"," 2023,\n"," up to $5,000,\n"," Tom Narayan,\n"," RBC Capital Markets Lead Equity Analyst,\n"," Global Autos,\n"," Yahoo Finance,\n"," Narayan,\n"," Tesla,\n"," Yahoo Finance)"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["help(doc.ents[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0fquYYZdKYEU","executionInfo":{"status":"ok","timestamp":1681197357143,"user_tz":-330,"elapsed":7,"user":{"displayName":"Balaji Anandan","userId":"04377515888334806424"}},"outputId":"8c58b7b8-3d5b-40aa-cbb6-6f70c10073de"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Help on Span object:\n","\n","class Span(builtins.object)\n"," |  A slice from a Doc object.\n"," |  \n"," |  DOCS: https://spacy.io/api/span\n"," |  \n"," |  Methods defined here:\n"," |  \n"," |  __eq__(self, value, /)\n"," |      Return self==value.\n"," |  \n"," |  __ge__(self, value, /)\n"," |      Return self>=value.\n"," |  \n"," |  __getitem__(...)\n"," |      Get a `Token` or a `Span` object\n"," |      \n"," |      i (int or tuple): The index of the token within the span, or slice of\n"," |          the span to get.\n"," |      RETURNS (Token or Span): The token at `span[i]`.\n"," |      \n"," |      DOCS: https://spacy.io/api/span#getitem\n"," |  \n"," |  __gt__(self, value, /)\n"," |      Return self>value.\n"," |  \n"," |  __hash__(self, /)\n"," |      Return hash(self).\n"," |  \n"," |  __iter__(...)\n"," |      Iterate over `Token` objects.\n"," |      \n"," |      YIELDS (Token): A `Token` object.\n"," |      \n"," |      DOCS: https://spacy.io/api/span#iter\n"," |  \n"," |  __le__(self, value, /)\n"," |      Return self<=value.\n"," |  \n"," |  __len__(...)\n"," |      Get the number of tokens in the span.\n"," |      \n"," |      RETURNS (int): The number of tokens in the span.\n"," |      \n"," |      DOCS: https://spacy.io/api/span#len\n"," |  \n"," |  __lt__(self, value, /)\n"," |      Return self<value.\n"," |  \n"," |  __ne__(self, value, /)\n"," |      Return self!=value.\n"," |  \n"," |  __reduce__(...)\n"," |      Span.__reduce__(self)\n"," |  \n"," |  __repr__(self, /)\n"," |      Return repr(self).\n"," |  \n"," |  as_doc(...)\n"," |      Span.as_doc(self, *, bool copy_user_data=False, array_head=None, array=None)\n"," |      Create a `Doc` object with a copy of the `Span`'s data.\n"," |      \n"," |              copy_user_data (bool): Whether or not to copy the original doc's user data.\n"," |              array_head (tuple): `Doc` array attrs, can be passed in to speed up computation.\n"," |              array (ndarray): `Doc` as array, can be passed in to speed up computation.\n"," |              RETURNS (Doc): The `Doc` copy of the span.\n"," |      \n"," |              DOCS: https://spacy.io/api/span#as_doc\n"," |  \n"," |  char_span(...)\n"," |      Span.char_span(self, int start_idx, int end_idx, label=0, kb_id=0, vector=None, id=0, alignment_mode='strict', span_id=0)\n"," |      Create a `Span` object from the slice `span.text[start : end]`.\n"," |      \n"," |              start (int): The index of the first character of the span.\n"," |              end (int): The index of the first character after the span.\n"," |              label (Union[int, str]): A label to attach to the Span, e.g. for\n"," |                  named entities.\n"," |              kb_id (Union[int, str]):  An ID from a KB to capture the meaning of a named entity.\n"," |              vector (ndarray[ndim=1, dtype='float32']): A meaning representation of\n"," |                  the span.\n"," |              id (Union[int, str]): Unused.\n"," |              alignment_mode (str): How character indices are aligned to token\n"," |                  boundaries. Options: \"strict\" (character indices must be aligned\n"," |                  with token boundaries), \"contract\" (span of all tokens completely\n"," |                  within the character span), \"expand\" (span of all tokens at least\n"," |                  partially covered by the character span). Defaults to \"strict\".\n"," |              span_id (Union[int, str]): An identifier to associate with the span.\n"," |              RETURNS (Span): The newly constructed object.\n"," |  \n"," |  get_lca_matrix(...)\n"," |      Span.get_lca_matrix(self)\n"," |      Calculates a matrix of Lowest Common Ancestors (LCA) for a given\n"," |              `Span`, where LCA[i, j] is the index of the lowest common ancestor among\n"," |              the tokens span[i] and span[j]. If they have no common ancestor within\n"," |              the span, LCA[i, j] will be -1.\n"," |      \n"," |              RETURNS (np.array[ndim=2, dtype=numpy.int32]): LCA matrix with shape\n"," |                  (n, n), where n = len(self).\n"," |      \n"," |              DOCS: https://spacy.io/api/span#get_lca_matrix\n"," |  \n"," |  similarity(...)\n"," |      Span.similarity(self, other)\n"," |      Make a semantic similarity estimate. The default estimate is cosine\n"," |              similarity using an average of word vectors.\n"," |      \n"," |              other (object): The object to compare with. By default, accepts `Doc`,\n"," |                  `Span`, `Token` and `Lexeme` objects.\n"," |              RETURNS (float): A scalar similarity score. Higher is more similar.\n"," |      \n"," |              DOCS: https://spacy.io/api/span#similarity\n"," |  \n"," |  to_array(...)\n"," |      Span.to_array(self, py_attr_ids) -> ndarray\n"," |      Given a list of M attribute IDs, export the tokens to a numpy\n"," |              `ndarray` of shape `(N, M)`, where `N` is the length of the document.\n"," |              The values will be 32-bit integers.\n"," |      \n"," |              attr_ids (list[int]): A list of attribute ID ints.\n"," |              RETURNS (numpy.ndarray[long, ndim=2]): A feature matrix, with one row\n"," |                  per word, and one column per attribute indicated in the input\n"," |                  `attr_ids`.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Class methods defined here:\n"," |  \n"," |  get_extension(...) from builtins.type\n"," |      Span.get_extension(type cls, name)\n"," |      Look up a previously registered extension by name.\n"," |      \n"," |              name (str): Name of the extension.\n"," |              RETURNS (tuple): A `(default, method, getter, setter)` tuple.\n"," |      \n"," |              DOCS: https://spacy.io/api/span#get_extension\n"," |  \n"," |  has_extension(...) from builtins.type\n"," |      Span.has_extension(type cls, name)\n"," |      Check whether an extension has been registered.\n"," |      \n"," |              name (str): Name of the extension.\n"," |              RETURNS (bool): Whether the extension has been registered.\n"," |      \n"," |              DOCS: https://spacy.io/api/span#has_extension\n"," |  \n"," |  remove_extension(...) from builtins.type\n"," |      Span.remove_extension(type cls, name)\n"," |      Remove a previously registered extension.\n"," |      \n"," |              name (str): Name of the extension.\n"," |              RETURNS (tuple): A `(default, method, getter, setter)` tuple of the\n"," |                  removed extension.\n"," |      \n"," |              DOCS: https://spacy.io/api/span#remove_extension\n"," |  \n"," |  set_extension(...) from builtins.type\n"," |      Span.set_extension(type cls, name, **kwargs)\n"," |      Define a custom attribute which becomes available as `Span._`.\n"," |      \n"," |              name (str): Name of the attribute to set.\n"," |              default: Optional default value of the attribute.\n"," |              getter (callable): Optional getter function.\n"," |              setter (callable): Optional setter function.\n"," |              method (callable): Optional method for method extension.\n"," |              force (bool): Force overwriting existing attribute.\n"," |      \n"," |              DOCS: https://spacy.io/api/span#set_extension\n"," |              USAGE: https://spacy.io/usage/processing-pipelines#custom-components-attributes\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Static methods defined here:\n"," |  \n"," |  __new__(*args, **kwargs) from builtins.type\n"," |      Create and return a new object.  See help(type) for accurate signature.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data descriptors defined here:\n"," |  \n"," |  conjuncts\n"," |      Tokens that are conjoined to the span's root.\n"," |      \n"," |      RETURNS (tuple): A tuple of Token objects.\n"," |      \n"," |      DOCS: https://spacy.io/api/span#lefts\n"," |  \n"," |  doc\n"," |  \n"," |  end\n"," |  \n"," |  end_char\n"," |  \n"," |  ent_id\n"," |      RETURNS (uint64): The entity ID.\n"," |  \n"," |  ent_id_\n"," |      RETURNS (str): The (string) entity ID.\n"," |  \n"," |  ents\n"," |      The named entities that fall completely within the span. Returns\n"," |      a tuple of `Span` objects.\n"," |      \n"," |      RETURNS (tuple): Entities in the span, one `Span` per entity.\n"," |      \n"," |      DOCS: https://spacy.io/api/span#ents\n"," |  \n"," |  has_vector\n"," |      A boolean value indicating whether a word vector is associated with\n"," |      the object.\n"," |      \n"," |      RETURNS (bool): Whether a word vector is associated with the object.\n"," |      \n"," |      DOCS: https://spacy.io/api/span#has_vector\n"," |  \n"," |  id\n"," |  \n"," |  id_\n"," |      RETURNS (str): The span's ID.\n"," |  \n"," |  kb_id\n"," |  \n"," |  kb_id_\n"," |      RETURNS (str): The span's KB ID.\n"," |  \n"," |  label\n"," |  \n"," |  label_\n"," |      RETURNS (str): The span's label.\n"," |  \n"," |  lefts\n"," |      Tokens that are to the left of the span, whose head is within the\n"," |      `Span`.\n"," |      \n"," |      YIELDS (Token):A left-child of a token of the span.\n"," |      \n"," |      DOCS: https://spacy.io/api/span#lefts\n"," |  \n"," |  lemma_\n"," |      RETURNS (str): The span's lemma.\n"," |  \n"," |  n_lefts\n"," |      The number of tokens that are to the left of the span, whose\n"," |      heads are within the span.\n"," |      \n"," |      RETURNS (int): The number of leftward immediate children of the\n"," |          span, in the syntactic dependency parse.\n"," |      \n"," |      DOCS: https://spacy.io/api/span#n_lefts\n"," |  \n"," |  n_rights\n"," |      The number of tokens that are to the right of the span, whose\n"," |      heads are within the span.\n"," |      \n"," |      RETURNS (int): The number of rightward immediate children of the\n"," |          span, in the syntactic dependency parse.\n"," |      \n"," |      DOCS: https://spacy.io/api/span#n_rights\n"," |  \n"," |  noun_chunks\n"," |      Iterate over the base noun phrases in the span. Yields base\n"," |      noun-phrase #[code Span] objects, if the language has a noun chunk iterator.\n"," |      Raises a NotImplementedError otherwise.\n"," |      \n"," |      A base noun phrase, or \"NP chunk\", is a noun\n"," |      phrase that does not permit other NPs to be nested within it – so no\n"," |      NP-level coordination, no prepositional phrases, and no relative\n"," |      clauses.\n"," |      \n"," |      YIELDS (Span): Noun chunks in the span.\n"," |      \n"," |      DOCS: https://spacy.io/api/span#noun_chunks\n"," |  \n"," |  orth_\n"," |      Verbatim text content (identical to `Span.text`). Exists mostly for\n"," |      consistency with other attributes.\n"," |      \n"," |      RETURNS (str): The span's text.\n"," |  \n"," |  rights\n"," |      Tokens that are to the right of the Span, whose head is within the\n"," |      `Span`.\n"," |      \n"," |      YIELDS (Token): A right-child of a token of the span.\n"," |      \n"," |      DOCS: https://spacy.io/api/span#rights\n"," |  \n"," |  root\n"," |      The token with the shortest path to the root of the\n"," |      sentence (or the root itself). If multiple tokens are equally\n"," |      high in the tree, the first token is taken.\n"," |      \n"," |      RETURNS (Token): The root token.\n"," |      \n"," |      DOCS: https://spacy.io/api/span#root\n"," |  \n"," |  sent\n"," |      Obtain the sentence that contains this span. If the given span\n"," |      crosses sentence boundaries, return only the first sentence\n"," |      to which it belongs.\n"," |      \n"," |      RETURNS (Span): The sentence span that the span is a part of.\n"," |  \n"," |  sentiment\n"," |      RETURNS (float): A scalar value indicating the positivity or\n"," |      negativity of the span.\n"," |  \n"," |  sents\n"," |      Obtain the sentences that contain this span. If the given span\n"," |      crosses sentence boundaries, return all sentences it is a part of.\n"," |      \n"," |      RETURNS (Iterable[Span]): All sentences that the span is a part of.\n"," |      \n"," |       DOCS: https://spacy.io/api/span#sents\n"," |  \n"," |  start\n"," |  \n"," |  start_char\n"," |  \n"," |  subtree\n"," |      Tokens within the span and tokens which descend from them.\n"," |      \n"," |      YIELDS (Token): A token within the span, or a descendant from it.\n"," |      \n"," |      DOCS: https://spacy.io/api/span#subtree\n"," |  \n"," |  tensor\n"," |      The span's slice of the doc's tensor.\n"," |      \n"," |      RETURNS (ndarray[ndim=2, dtype='float32']): A 2D numpy or cupy array\n"," |          representing the span's semantics.\n"," |  \n"," |  text\n"," |      RETURNS (str): The original verbatim text of the span.\n"," |  \n"," |  text_with_ws\n"," |      The text content of the span with a trailing whitespace character if\n"," |      the last token has one.\n"," |      \n"," |      RETURNS (str): The text content of the span (with trailing\n"," |          whitespace).\n"," |  \n"," |  vector\n"," |      A real-valued meaning representation. Defaults to an average of the\n"," |      token vectors.\n"," |      \n"," |      RETURNS (numpy.ndarray[ndim=1, dtype='float32']): A 1D numpy array\n"," |          representing the span's semantics.\n"," |      \n"," |      DOCS: https://spacy.io/api/span#vector\n"," |  \n"," |  vector_norm\n"," |      The L2 norm of the span's vector representation.\n"," |      \n"," |      RETURNS (float): The L2 norm of the vector representation.\n"," |      \n"," |      DOCS: https://spacy.io/api/span#vector_norm\n"," |  \n"," |  vocab\n"," |      RETURNS (Vocab): The Span's Doc's vocab.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data and other attributes defined here:\n"," |  \n"," |  __pyx_vtable__ = <capsule object NULL>\n","\n"]}]},{"cell_type":"code","source":["doc.ents[0].label_"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"M72JturjK3uQ","executionInfo":{"status":"ok","timestamp":1681197396440,"user_tz":-330,"elapsed":17,"user":{"displayName":"Balaji Anandan","userId":"04377515888334806424"}},"outputId":"4b6186d8-50be-4a17-9003-3fe342b3be56"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'ORG'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["for ent in doc.ents:\n","  print(ent.label_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pw003vmELGC5","executionInfo":{"status":"ok","timestamp":1681197476969,"user_tz":-330,"elapsed":5,"user":{"displayName":"Balaji Anandan","userId":"04377515888334806424"}},"outputId":"199f3ff0-b8b9-4d3c-ba63-b42827f17ff0"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["ORG\n","GPE\n","ORDINAL\n","DATE\n","MONEY\n","PERSON\n","ORG\n","ORG\n","ORG\n","PERSON\n","ORG\n","ORG\n"]}]},{"cell_type":"code","source":["for ent in doc.ents:\n","  print(f\"{ent.label_} : {ent.text}\" )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RhGp_PwpLaXy","executionInfo":{"status":"ok","timestamp":1681197665410,"user_tz":-330,"elapsed":4,"user":{"displayName":"Balaji Anandan","userId":"04377515888334806424"}},"outputId":"eadf5d9f-2502-4af1-cfc7-5a2978cd8ef1"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["ORG : Tesla\n","GPE : U.S.\n","ORDINAL : third\n","DATE : 2023\n","MONEY : up to $5,000\n","PERSON : Tom Narayan\n","ORG : RBC Capital Markets Lead Equity Analyst\n","ORG : Global Autos\n","ORG : Yahoo Finance\n","PERSON : Narayan\n","ORG : Tesla\n","ORG : Yahoo Finance\n"]}]},{"cell_type":"code","source":["org_list = []\n","for ent in doc.ents:\n","  if ent.label_ == 'ORG':\n","    org_list.append(ent.text)\n","print(org_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N0vfZ_MGNZJY","executionInfo":{"status":"ok","timestamp":1681198187005,"user_tz":-330,"elapsed":4,"user":{"displayName":"Balaji Anandan","userId":"04377515888334806424"}},"outputId":"b4629558-bc85-402f-c93c-dd7c172b697f"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["['Tesla', 'RBC Capital Markets Lead Equity Analyst', 'Global Autos', 'Yahoo Finance', 'Tesla', 'Yahoo Finance']\n"]}]},{"cell_type":"code","source":["org_list = [ent.text for ent in doc.ents if ent.label_ == 'ORG']\n","org_list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9dWT2TTbMIQ4","executionInfo":{"status":"ok","timestamp":1681198174997,"user_tz":-330,"elapsed":1944,"user":{"displayName":"Balaji Anandan","userId":"04377515888334806424"}},"outputId":"b499e11b-7012-49ea-c12e-7dfdf1984f3b"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Tesla',\n"," 'RBC Capital Markets Lead Equity Analyst',\n"," 'Global Autos',\n"," 'Yahoo Finance',\n"," 'Tesla',\n"," 'Yahoo Finance']"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":[],"metadata":{"id":"mfXrb5CEN3Z5"},"execution_count":null,"outputs":[]}]}