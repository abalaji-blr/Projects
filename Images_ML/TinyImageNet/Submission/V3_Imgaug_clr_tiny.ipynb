{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dUXjQNm7YgAr"
   },
   "source": [
    "# Tiny ImageNet - Augmentation using Imgaug, CLR, Custom Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AjZuFSFtxGtS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mDa7Q2VP6Eld"
   },
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616
    },
    "colab_type": "code",
    "id": "OlvU-cRiYW9A",
    "outputId": "d64dd533-3927-4c53-864f-e01217233498"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imgaug in /usr/local/lib/python3.6/dist-packages (0.2.8)\n",
      "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from imgaug) (2.4.1)\n",
      "Collecting numpy>=1.15.0 (from imgaug)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/d5/4f8410ac303e690144f0a0603c4b8fd3b986feb2749c435f7cdbb288f17e/numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 17.3MB 2.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.1.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.11.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from imgaug) (4.1.1)\n",
      "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.6.4.post2)\n",
      "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug) (0.13.1)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug) (3.4.5.20)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug) (3.0.3)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->imgaug) (0.46)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug) (1.0.2)\n",
      "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug) (2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (2.5.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (2.3.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.8->scikit-image>=0.11.0->imgaug) (4.4.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug) (40.9.0)\n",
      "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mdatascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy\n",
      "  Found existing installation: numpy 1.14.6\n",
      "    Uninstalling numpy-1.14.6:\n",
      "      Successfully uninstalled numpy-1.14.6\n",
      "Successfully installed numpy-1.16.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "colab_type": "code",
    "id": "4san0jbQbnyc",
    "outputId": "9d599798-817a-4a2f-b735-4f6c9eb17682"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-image\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/ab/674e168bf7d0bc597218b3bec858d02c23fbac9ec1fec9cad878c6cee95f/scikit_image-0.15.0-cp36-cp36m-manylinux1_x86_64.whl (26.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 26.3MB 1.8MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.4.1)\n",
      "Collecting pillow>=4.3.0 (from scikit-image)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/c2/f84b1e57416755e967236468dcfb0fad7fd911f707185efc4ba8834a1a94/Pillow-6.0.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.0MB 16.7MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (3.0.3)\n",
      "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from imageio>=2.0.1->scikit-image) (1.16.2)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.3.1)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.5.3)\n",
      "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image) (4.4.0)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (40.9.0)\n",
      "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
      "Installing collected packages: pillow, scikit-image\n",
      "  Found existing installation: Pillow 4.1.1\n",
      "    Uninstalling Pillow-4.1.1:\n",
      "      Successfully uninstalled Pillow-4.1.1\n",
      "  Found existing installation: scikit-image 0.13.1\n",
      "    Uninstalling scikit-image-0.13.1:\n",
      "      Successfully uninstalled scikit-image-0.13.1\n",
      "Successfully installed pillow-6.0.0 scikit-image-0.15.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "PIL"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install --upgrade scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "dvyNon6NY1-m",
    "outputId": "6037dec4-d697-41da-cc3e-d8da18f513cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "\n",
    "!cp '/content/gdrive/My Drive/App/Tiny/MyUtils.zip' /content\n",
    "!unzip -q /content/MyUtils.zip\n",
    "\n",
    "!cp '/content/gdrive/My Drive/App/Tiny/Mod/tiny-imagenet-200.zip' /content\n",
    "!unzip -q /content/tiny-imagenet-200.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E5_ZfClN6XXs"
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JMAA3dfI6zfp"
   },
   "source": [
    "### Custom ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pad6YH1p6vca"
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import AveragePooling2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import SeparableConv2D\n",
    "\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import add\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "'''\n",
    "    Standard ResNet50 is too deep for Tiny ImageNet dataset.\n",
    "    Let's build a custom one.\n",
    "\n",
    "    1) Instead of 7x7 filter use 5,5 with stride 1\n",
    "    2) Experiment about removing MaxPool in the entry block\n",
    "       Reason: Don't want to reduce the input dimension.\n",
    "    3) About repetition resuidal block - remove last set.\n",
    "       Reason: it's too deep for this dataset.\n",
    "       Also, we want to go beyond the object and identify scenes as well.\n",
    "    4) About kernel count - experiment the following\n",
    "        * [64, 128, 256]\n",
    "        * or [128, 256, 512]\n",
    "        * Make sure the params are well within the limit\n",
    "    4) Remove Dense Layer\n",
    "        * Use GAP\n",
    "        * or 1x1 Conv.\n",
    "        * By default, network uses 'Avg pool' before flatten.\n",
    "          Do we need that if we go with GAP?\n",
    "    5) Stretch goal: Experiment with SeparableConv2D() instead of Conv2D().\n",
    "'''\n",
    "class CustomResNet:\n",
    "    @staticmethod\n",
    "    def entry_block(input, num_filters):\n",
    "        '''\n",
    "        1. In the entry block, use filter 5x5 with stride 1 instead of 7x7.\n",
    "        2. Optionally think about ignoring the Maxpool in the entry block.\n",
    "        Idea is, input 64x64 => before the resuidal block, retain same input\n",
    "        shape or reduced to just 32x32.\n",
    "        '''\n",
    "        ## CONV -> BN -> ACT -> MaxPool\n",
    "        x = Conv2D(num_filters, (5,5), padding='same')(input)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = ZeroPadding2D((1,1))(x) # next one is max pool, do prep the data accordingly.\n",
    "        block_output = MaxPooling2D((3,3), strides=(2,2))(x)\n",
    "        return block_output\n",
    "\n",
    "    '''\n",
    "    1x1 CONV -> 3x3 CONV -> 1x1 CONV\n",
    "    '''\n",
    "    @staticmethod\n",
    "    def residual_block(input_data, num_filters, stride):\n",
    "\n",
    "        short_cut = input_data\n",
    "\n",
    "        # BN -> Act -> Conv2D(1,1)\n",
    "        bn1 = BatchNormalization()(input_data)\n",
    "        act1 = Activation('relu')(bn1)\n",
    "        conv1 = Conv2D(int(num_filters * 0.25), (1,1))(act1)\n",
    "\n",
    "        # BN -> Act -> Conv2D(3,3)\n",
    "        bn2 = BatchNormalization()(conv1)\n",
    "        act2 = Activation('relu')(bn2)\n",
    "        conv2 = Conv2D(int(num_filters * 0.25), (3,3), strides=stride, padding='same')(act2)\n",
    "\n",
    "        # BN -> Act -> Conv2D(1,1)\n",
    "        bn3 = BatchNormalization()(conv2)\n",
    "        act3 = Activation('relu')(bn3)\n",
    "        conv3 = Conv2D(num_filters, (1,1))(act3)\n",
    "\n",
    "        # need to add with short cut.\n",
    "        x = add([conv3, short_cut])\n",
    "        return x\n",
    "\n",
    "    '''\n",
    "    Entry block of the residual network, which needs to reduce\n",
    "    the spatial volume. Basically, need to create the CONV layer\n",
    "    in the short_cut-branch to match the dimension from the main-branch.\n",
    "    '''\n",
    "    @staticmethod\n",
    "    def residual_block_reduce(input_data, num_filters, stride):\n",
    "        short_cut = input_data\n",
    "\n",
    "        # BN -> Act -> Conv2D(1,1)\n",
    "        bn1 = BatchNormalization()(input_data)\n",
    "        act1 = Activation('relu')(bn1)\n",
    "        conv1 = Conv2D(int(num_filters * 0.25), (1, 1))(act1)\n",
    "\n",
    "        # BN -> Act -> Conv2D(3,3)\n",
    "        bn2 = BatchNormalization()(conv1)\n",
    "        act2 = Activation('relu')(bn2)\n",
    "        conv2 = Conv2D(int(num_filters * 0.25), (3, 3),\n",
    "                       strides=stride, padding='same')(act2)\n",
    "\n",
    "        # BN -> Act -> Conv2D(1,1)\n",
    "        bn3 = BatchNormalization()(conv2)\n",
    "        act3 = Activation('relu')(bn3)\n",
    "        conv3 = Conv2D(num_filters, (1, 1))(act3)\n",
    "\n",
    "        ## to match the dimension from the main-branch with short-cut-branch\n",
    "        ## apply Conv 1,1 in the short-cut branch, so addition of layers is possible.\n",
    "        short_cut = Conv2D(num_filters, (1,1), strides=stride)(act1)\n",
    "\n",
    "        # need to add with short cut.\n",
    "        x = add([conv3, short_cut])\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet(width, height, depth, num_classes, stages, filters):\n",
    "        \"\"\"Builds a custom ResNet like architecture.\n",
    "            Returns:\n",
    "            The keras `Model`.\n",
    "        \"\"\"\n",
    "        # get the input shape, channels last.\n",
    "        inputShape = (width, height, depth)\n",
    "\n",
    "        # get the input layer\n",
    "        inputs = Input(shape=inputShape)\n",
    "\n",
    "        ## before apply CONV, it's better to normalize the input\n",
    "        ## use BatchNorm, by default, channel last\n",
    "        x = BatchNormalization()(inputs)\n",
    "\n",
    "        ## build entry block\n",
    "        x = CustomResNet.entry_block(x, filters[0])\n",
    "\n",
    "        ## build the residual blocks for different stages\n",
    "        for i in range(0, len(stages)):\n",
    "            stride = (1,1) if i == 0 else (2,2)\n",
    "\n",
    "            # first block need to reduce the spatial size of input vol.\n",
    "            # in the short-cut-branch to enable concatenation.\n",
    "            x = CustomResNet.residual_block_reduce(x, filters[i+1], stride)\n",
    "\n",
    "            # depth of the residual block.\n",
    "            for j in range(0, stages[i]-1):\n",
    "               x = CustomResNet.residual_block(x, filters[i+1], (1,1))\n",
    "        \n",
    "        ## BN -> Act -> Ave. pooling\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        block_output = x\n",
    "        block_shape  = K.int_shape(x)\n",
    "\n",
    "        #try GlobalAvgPool instead of AvgPool\n",
    "        # input tensor 8x8x512\n",
    "        x = SeparableConv2D(block_shape[3] // 2, (3, 3))(block_output)\n",
    "\n",
    "        # reduce the volume to num_classes\n",
    "        x = SeparableConv2D(num_classes, (3,3))(x)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "         \n",
    "        #x = AveragePooling2D((8,8))(x)\n",
    "        \n",
    "\n",
    "        ## outputs\n",
    "        #x = Flatten()(x)\n",
    "        #x = Dense(num_classes)(x)\n",
    "        \n",
    "        outputs = Activation('softmax')(x)\n",
    "        \n",
    "\n",
    "        ## build the model\n",
    "        model = Model(inputs, outputs, name='custom_resnet')\n",
    "        return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5qNU6lno66Wl"
   },
   "source": [
    "### Imports and Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XbaDvkJuZJsY",
    "outputId": "9e3a9bee-5110-4fc1-8ea7-d782135abfc3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "nn\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "## Learning Rate Scheduler\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "##from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from MyUtils.Dataset import DatasetLoader\n",
    "from MyUtils.CustomResNet import CustomResNet\n",
    "from MyUtils.CLR import CyclicLR\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "import cv2\n",
    "\n",
    "## configurations ##\n",
    "ROOT_DIR='/content'\n",
    "IMAGE_ROOT_DIR=os.path.join(ROOT_DIR, 'tiny-imagenet-200')\n",
    "\n",
    "# utilities.\n",
    "UTILS_ROOT_DIR='/content'\n",
    "MY_UTILS_DIR= os.path.join(UTILS_ROOT_DIR,'MyUtils')\n",
    "SUPPORT_FILES_DIR=os.path.join(MY_UTILS_DIR, 'SupportFiles')\n",
    "\n",
    "\n",
    "train_data_dir = os.path.join(IMAGE_ROOT_DIR,'train')\n",
    "validation_data_dir = os.path.join(IMAGE_ROOT_DIR, 'val')\n",
    "num_train_samples = 100000\n",
    "num_validation_samples = 10000\n",
    "\n",
    "## colab crashes, so need to multiple runs - may be 25 epochs three times.\n",
    "epochs = 50\n",
    "batch_size = 256\n",
    "\n",
    "img_height = 64\n",
    "img_width  = 64\n",
    "num_channel = 3\n",
    "num_classes = 200\n",
    "\n",
    "## in the case of poly decay.\n",
    "INIT_LR = 1e-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xxyvkJKd7PHy"
   },
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5392
    },
    "colab_type": "code",
    "id": "KidIv_wFZYJX",
    "outputId": "425f580d-3f83-40d0-da9d-d028c9ef1ef4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 3)    12          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 64)   4864        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 66, 66, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 64)   0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 64)   256         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 32)   2080        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 32)   128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 32)   9248        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 32)   128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 128)  4224        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 128)  8320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 128)  0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 128)  512         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 32)   4128        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 32)   128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 32)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 32)   9248        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 32)   128         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 32)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 128)  4224        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 128)  0           conv2d_8[0][0]                   \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 128)  512         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 128)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 32)   4128        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 32)   128         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 32)   9248        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 32)   128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 128)  4224        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 128)  0           conv2d_11[0][0]                  \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 128)  512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 64)   8256        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 64)   256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 64)   36928       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 64)   256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 256)  16640       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 256)  33024       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 256)  0           conv2d_14[0][0]                  \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 256)  1024        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 256)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 64)   16448       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 64)   256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 64)   36928       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 64)   256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 64)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 256)  16640       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 256)  0           conv2d_18[0][0]                  \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 256)  1024        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 256)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 64)   16448       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 64)   256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 64)   36928       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 64)   256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 256)  16640       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 256)  0           conv2d_21[0][0]                  \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 256)  1024        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 256)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 64)   16448       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 64)   256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 64)   36928       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 64)   256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 256)  16640       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 16, 256)  0           conv2d_24[0][0]                  \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 256)  1024        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 256)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 128)  32896       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 128)  512         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 128)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 8, 8, 128)    147584      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 8, 128)    512         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 8, 8, 128)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 8, 8, 512)    66048       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 8, 512)    131584      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 512)    0           conv2d_27[0][0]                  \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 8, 8, 512)    2048        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 8, 512)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 8, 8, 128)    65664       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 8, 8, 128)    512         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 8, 8, 128)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 8, 8, 128)    147584      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 8, 8, 128)    512         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 8, 8, 128)    0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 8, 512)    66048       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 512)    0           conv2d_31[0][0]                  \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 8, 512)    2048        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 8, 8, 512)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 8, 8, 128)    65664       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 8, 8, 128)    512         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 8, 8, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 8, 128)    147584      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 8, 8, 128)    512         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 8, 8, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 8, 8, 512)    66048       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 512)    0           conv2d_34[0][0]                  \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 8, 8, 512)    2048        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 8, 8, 512)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 8, 8, 128)    65664       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 8, 8, 128)    512         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 8, 8, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 8, 8, 128)    147584      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 8, 8, 128)    512         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 8, 8, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 8, 8, 512)    66048       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 512)    0           conv2d_37[0][0]                  \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 8, 8, 512)    2048        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 8, 8, 512)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 8, 8, 128)    65664       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 8, 8, 128)    512         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 8, 8, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 8, 8, 128)    147584      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 8, 8, 128)    512         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 8, 8, 128)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 8, 8, 512)    66048       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 8, 8, 512)    0           conv2d_40[0][0]                  \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 8, 8, 512)    2048        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 8, 8, 512)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 8, 8, 128)    65664       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 8, 8, 128)    512         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 8, 8, 128)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 8, 8, 128)    147584      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 8, 8, 128)    512         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 8, 8, 128)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 8, 8, 512)    66048       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 8, 8, 512)    0           conv2d_43[0][0]                  \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 8, 8, 512)    2048        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 8, 8, 512)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 6, 6, 256)    135936      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCo (None, 4, 4, 200)    53704       separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 200)          0           separable_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 200)          0           global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 2,360,468\n",
      "Trainable params: 2,346,766\n",
      "Non-trainable params: 13,702\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## 1. Use CustomResNet - which uses GAP, SeparableConv2D.\n",
    "## 2. Also, as we need shorter resnet with shortcut connections, \n",
    "##    remove the last repetition of residual block.\n",
    "## 3. As we need wider network - use 128,256,512 depth'channels in residual blocks.\n",
    "##    Need to experiment [256,512,1024] as well to see whether that provides better accuracy.\n",
    "###\n",
    "\n",
    "model = CustomResNet.build_resnet(64, 64,3, 200, (3,4,6), (64,128,256,512))\n",
    "                     \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qFyRG6BTZdBI"
   },
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=INIT_LR, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RlDezbb17Wwy"
   },
   "source": [
    "## Cyclic LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wSdSwsFVZiC0"
   },
   "outputs": [],
   "source": [
    "## define the poly decay\n",
    "## input is epoch number and returns new alpha (lr)\n",
    "def poly_decay(epoch):\n",
    "  maxEpochs = epochs\n",
    "  base_lr   = INIT_LR\n",
    "  power     = 1.0\n",
    "  \n",
    "  # compute new lr\n",
    "  new_lr = base_lr * ( 1 - (epoch / float(maxEpochs))) ** power\n",
    "  \n",
    "  # new learning rate\n",
    "  return new_lr\n",
    "  \n",
    "##### CLR #########\n",
    "## Experiment with CLR instead of poly decay\n",
    "clr = CyclicLR(base_lr=0.001, max_lr=0.1, mode='exp_range')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tIO76iTqZmwk"
   },
   "outputs": [],
   "source": [
    "## to save the best model \n",
    "\n",
    "checkpoint = ModelCheckpoint('/content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5', monitor='val_acc', verbose=1, save_best_only=True)\n",
    "\n",
    "##callback_list = [checkpoint, LearningRateScheduler(poly_decay)]\n",
    "\n",
    "callback_list = [checkpoint, clr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mKoEalkj7e17"
   },
   "source": [
    "## Genertors for Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "vyWuL11mZuCj",
    "outputId": "01ae6441-d405-4284-a38b-7661f7351a36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 images belonging to 200 classes.\n",
      "dict_keys(['n01443537', 'n01629819', 'n01641577', 'n01644900', 'n01698640', 'n01742172', 'n01768244', 'n01770393', 'n01774384', 'n01774750', 'n01784675', 'n01855672', 'n01882714', 'n01910747', 'n01917289', 'n01944390', 'n01945685', 'n01950731', 'n01983481', 'n01984695', 'n02002724', 'n02056570', 'n02058221', 'n02074367', 'n02085620', 'n02094433', 'n02099601', 'n02099712', 'n02106662', 'n02113799', 'n02123045', 'n02123394', 'n02124075', 'n02125311', 'n02129165', 'n02132136', 'n02165456', 'n02190166', 'n02206856', 'n02226429', 'n02231487', 'n02233338', 'n02236044', 'n02268443', 'n02279972', 'n02281406', 'n02321529', 'n02364673', 'n02395406', 'n02403003', 'n02410509', 'n02415577', 'n02423022', 'n02437312', 'n02480495', 'n02481823', 'n02486410', 'n02504458', 'n02509815', 'n02666196', 'n02669723', 'n02699494', 'n02730930', 'n02769748', 'n02788148', 'n02791270', 'n02793495', 'n02795169', 'n02802426', 'n02808440', 'n02814533', 'n02814860', 'n02815834', 'n02823428', 'n02837789', 'n02841315', 'n02843684', 'n02883205', 'n02892201', 'n02906734', 'n02909870', 'n02917067', 'n02927161', 'n02948072', 'n02950826', 'n02963159', 'n02977058', 'n02988304', 'n02999410', 'n03014705', 'n03026506', 'n03042490', 'n03085013', 'n03089624', 'n03100240', 'n03126707', 'n03160309', 'n03179701', 'n03201208', 'n03250847', 'n03255030', 'n03355925', 'n03388043', 'n03393912', 'n03400231', 'n03404251', 'n03424325', 'n03444034', 'n03447447', 'n03544143', 'n03584254', 'n03599486', 'n03617480', 'n03637318', 'n03649909', 'n03662601', 'n03670208', 'n03706229', 'n03733131', 'n03763968', 'n03770439', 'n03796401', 'n03804744', 'n03814639', 'n03837869', 'n03838899', 'n03854065', 'n03891332', 'n03902125', 'n03930313', 'n03937543', 'n03970156', 'n03976657', 'n03977966', 'n03980874', 'n03983396', 'n03992509', 'n04008634', 'n04023962', 'n04067472', 'n04070727', 'n04074963', 'n04099969', 'n04118538', 'n04133789', 'n04146614', 'n04149813', 'n04179913', 'n04251144', 'n04254777', 'n04259630', 'n04265275', 'n04275548', 'n04285008', 'n04311004', 'n04328186', 'n04356056', 'n04366367', 'n04371430', 'n04376876', 'n04398044', 'n04399382', 'n04417672', 'n04456115', 'n04465501', 'n04486054', 'n04487081', 'n04501370', 'n04507155', 'n04532106', 'n04532670', 'n04540053', 'n04560804', 'n04562935', 'n04596742', 'n04597913', 'n06596364', 'n07579787', 'n07583066', 'n07614500', 'n07615774', 'n07695742', 'n07711569', 'n07715103', 'n07720875', 'n07734744', 'n07747607', 'n07749582', 'n07753592', 'n07768694', 'n07871810', 'n07873807', 'n07875152', 'n07920052', 'n09193705', 'n09246464', 'n09256479', 'n09332890', 'n09428293', 'n12267677'])\n",
      "dict_values([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199])\n",
      "Found 10000 images belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "rMean = 122.46\n",
    "gMean = 114.25\n",
    "bMean = 101.36\n",
    "\n",
    "def mean_subtraction(img):\n",
    "    (r_init, g_init, b_init) = cv2.split(img.astype('float32'))\n",
    "    \n",
    "    r = r_init - rMean\n",
    "    g = g_init - gMean\n",
    "    b = b_init - bMean\n",
    "    \n",
    "    new_img = cv2.merge([r, g, b])\n",
    "    return new_img\n",
    "  \n",
    "\n",
    "## preprocess image and training augmentation\n",
    "train_datagen = ImageDataGenerator(rotation_range=18, \n",
    "                                   zoom_range=0.15, \n",
    "                                   width_shift_range=0.2, \n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.15, \n",
    "                                   horizontal_flip=True, \n",
    "                                   fill_mode='nearest',\n",
    "                                    preprocessing_function=mean_subtraction)\n",
    "\n",
    "'''\n",
    "## Use imgaug augmentations.\n",
    "\n",
    "img_aug = iaa.Sequential([\n",
    "    iaa.GaussianBlur(sigma=(0.0, 3.0)),    # blur the images\n",
    "    iaa.Fliplr(0.5),                       # horizontally flip 50% of the images\n",
    "    iaa.Crop(px=(0, 16)),                  # crop images from each side by 0 to 16px (randomly chosen)\n",
    "    iaa.ContrastNormalization((0.5, 1.5)), # normalize the contrast\n",
    "    iaa.CropAndPad(percent=(-0.25, 0.25)), # crop and pad with black \n",
    "    iaa.Affine(scale=(0.5, 1.5)),          # zoom in and zoom out 50 to 150%\n",
    "    iaa.Affine(translate_px={\"x\": (-20, 20), \"y\": (-20, 20)}), # translate x & y 20 pixels independently\n",
    "    iaa.Affine(rotate=(-18, 18)),          # rotate\n",
    "    iaa.Affine(shear=(-15, 15)),           # shear\n",
    "    iaa.Sharpen(alpha=(0.0, 1.0), lightness=(0.75, 2.0)) # sharpen the image\n",
    "])\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=img_aug.augment_image)\n",
    "\n",
    "## train generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                    train_data_dir,\n",
    "                    target_size=(img_width, img_height),\n",
    "                    batch_size=batch_size,\n",
    "                    class_mode='categorical')\n",
    "\n",
    "label_dict = train_generator.class_indices\n",
    "\n",
    "print(label_dict.keys())\n",
    "print(label_dict.values())\n",
    "\n",
    "## validation generator\n",
    "#validation_datagen = ImageDataGenerator(preprocessing_function=mean_subtraction)\n",
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fp4Orniq7kP0"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vkjIWNap7sNa"
   },
   "source": [
    "### Epochs 1- 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3454
    },
    "colab_type": "code",
    "id": "4uB3OE02cFrH",
    "outputId": "8a95911d-0380-4cbf-f3b4-485339df05e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "390/390 [==============================] - 587s 2s/step - loss: 5.2986 - acc: 0.0045 - val_loss: 5.2982 - val_acc: 0.0057\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.00575, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n",
      "Epoch 2/50\n",
      "390/390 [==============================] - 573s 1s/step - loss: 5.2810 - acc: 0.0076 - val_loss: 5.2523 - val_acc: 0.0130\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.00575 to 0.01302, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n",
      "Epoch 3/50\n",
      "390/390 [==============================] - 583s 1s/step - loss: 5.0399 - acc: 0.0217 - val_loss: 5.0191 - val_acc: 0.0300\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.01302 to 0.02997, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n",
      "Epoch 4/50\n",
      "390/390 [==============================] - 583s 1s/step - loss: 4.8272 - acc: 0.0427 - val_loss: 5.4261 - val_acc: 0.0380\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.02997 to 0.03797, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n",
      "Epoch 5/50\n",
      "390/390 [==============================] - 584s 1s/step - loss: 4.6899 - acc: 0.0582 - val_loss: 4.6589 - val_acc: 0.0731\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.03797 to 0.07307, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n",
      "Epoch 6/50\n",
      "390/390 [==============================] - 585s 1s/step - loss: 4.5536 - acc: 0.0756 - val_loss: 4.7114 - val_acc: 0.0630\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.07307\n",
      "Epoch 7/50\n",
      "390/390 [==============================] - 586s 2s/step - loss: 4.4326 - acc: 0.0906 - val_loss: 4.3953 - val_acc: 0.0968\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.07307 to 0.09678, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n",
      "Epoch 8/50\n",
      "390/390 [==============================] - 586s 2s/step - loss: 4.3263 - acc: 0.1062 - val_loss: 4.2053 - val_acc: 0.1227\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.09678 to 0.12274, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n",
      "Epoch 9/50\n",
      "390/390 [==============================] - 587s 2s/step - loss: 4.2207 - acc: 0.1223 - val_loss: 4.0252 - val_acc: 0.1490\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.12274 to 0.14901, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n",
      "Epoch 10/50\n",
      "390/390 [==============================] - 587s 2s/step - loss: 4.1575 - acc: 0.1300 - val_loss: 4.1294 - val_acc: 0.1394\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.14901\n",
      "Epoch 11/50\n",
      "390/390 [==============================] - 586s 2s/step - loss: 4.2029 - acc: 0.1241 - val_loss: 4.4752 - val_acc: 0.1162\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.14901\n",
      "Epoch 12/50\n",
      "390/390 [==============================] - 588s 2s/step - loss: 4.2312 - acc: 0.1195 - val_loss: 4.3676 - val_acc: 0.1019\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.14901\n",
      "Epoch 13/50\n",
      "390/390 [==============================] - 584s 1s/step - loss: 4.2415 - acc: 0.1185 - val_loss: 4.4194 - val_acc: 0.1086\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.14901\n",
      "Epoch 14/50\n",
      "390/390 [==============================] - 584s 1s/step - loss: 4.2228 - acc: 0.1214 - val_loss: 4.3556 - val_acc: 0.1010\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.14901\n",
      "Epoch 15/50\n",
      "390/390 [==============================] - 584s 1s/step - loss: 4.1817 - acc: 0.1257 - val_loss: 4.2378 - val_acc: 0.1205\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.14901\n",
      "Epoch 16/50\n",
      "390/390 [==============================] - 585s 2s/step - loss: 4.0910 - acc: 0.1406 - val_loss: 4.7041 - val_acc: 0.1098\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.14901\n",
      "Epoch 17/50\n",
      "390/390 [==============================] - 586s 2s/step - loss: 3.9968 - acc: 0.1548 - val_loss: 3.9604 - val_acc: 0.1650\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.14901 to 0.16502, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n",
      "Epoch 18/50\n",
      "390/390 [==============================] - 585s 2s/step - loss: 3.9063 - acc: 0.1693 - val_loss: 3.8715 - val_acc: 0.1860\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.16502 to 0.18596, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n",
      "Epoch 19/50\n",
      "390/390 [==============================] - 582s 1s/step - loss: 3.8059 - acc: 0.1823 - val_loss: 3.5489 - val_acc: 0.2206\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.18596 to 0.22065, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n",
      "Epoch 20/50\n",
      "390/390 [==============================] - 587s 2s/step - loss: 3.7313 - acc: 0.1950 - val_loss: 3.4664 - val_acc: 0.2288\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.22065 to 0.22876, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n",
      "Epoch 21/50\n",
      "390/390 [==============================] - 585s 2s/step - loss: 3.7598 - acc: 0.1903 - val_loss: 3.8769 - val_acc: 0.1924\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.22876\n",
      "Epoch 22/50\n",
      "390/390 [==============================] - 583s 1s/step - loss: 3.8203 - acc: 0.1812 - val_loss: 3.8597 - val_acc: 0.1818\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.22876\n",
      "Epoch 23/50\n",
      "390/390 [==============================] - 585s 1s/step - loss: 3.8679 - acc: 0.1737 - val_loss: 4.5124 - val_acc: 0.1411\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.22876\n",
      "Epoch 24/50\n",
      "390/390 [==============================] - 582s 1s/step - loss: 3.8990 - acc: 0.1682 - val_loss: 4.0490 - val_acc: 0.1752\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.22876\n",
      "Epoch 25/50\n",
      "390/390 [==============================] - 582s 1s/step - loss: 3.9063 - acc: 0.1695 - val_loss: 4.0662 - val_acc: 0.1650\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.22876\n",
      "Epoch 26/50\n",
      "390/390 [==============================] - 586s 2s/step - loss: 3.8303 - acc: 0.1797 - val_loss: 3.9185 - val_acc: 0.1878\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.22876\n",
      "Epoch 27/50\n",
      "390/390 [==============================] - 583s 1s/step - loss: 3.7424 - acc: 0.1930 - val_loss: 3.6896 - val_acc: 0.2143\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.22876\n",
      "Epoch 28/50\n",
      "390/390 [==============================] - 583s 1s/step - loss: 3.6615 - acc: 0.2071 - val_loss: 3.4198 - val_acc: 0.2501\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.22876 to 0.25010, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n",
      "Epoch 29/50\n",
      "390/390 [==============================] - 584s 1s/step - loss: 3.5686 - acc: 0.2228 - val_loss: 3.2926 - val_acc: 0.2705\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.25010 to 0.27053, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n",
      "Epoch 30/50\n",
      "390/390 [==============================] - 582s 1s/step - loss: 3.4817 - acc: 0.2356 - val_loss: 3.1708 - val_acc: 0.2919\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.27053 to 0.29187, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n",
      "Epoch 31/50\n",
      "390/390 [==============================] - 583s 1s/step - loss: 3.4822 - acc: 0.2365 - val_loss: 3.2784 - val_acc: 0.2709\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.29187\n",
      "Epoch 32/50\n",
      "390/390 [==============================] - 583s 1s/step - loss: 3.5485 - acc: 0.2241 - val_loss: 3.5829 - val_acc: 0.2289\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.29187\n",
      "Epoch 33/50\n",
      "390/390 [==============================] - 586s 2s/step - loss: 3.6123 - acc: 0.2135 - val_loss: 3.5860 - val_acc: 0.2173\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.29187\n",
      "Epoch 34/50\n",
      "390/390 [==============================] - 583s 1s/step - loss: 3.6651 - acc: 0.2055 - val_loss: 3.8637 - val_acc: 0.2088\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.29187\n",
      "Epoch 35/50\n",
      "390/390 [==============================] - 585s 2s/step - loss: 3.6946 - acc: 0.1981 - val_loss: 3.6421 - val_acc: 0.2082\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.29187\n",
      "Epoch 36/50\n",
      "390/390 [==============================] - 585s 1s/step - loss: 3.6608 - acc: 0.2087 - val_loss: 3.4629 - val_acc: 0.2391\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.29187\n",
      "Epoch 37/50\n",
      "390/390 [==============================] - 586s 2s/step - loss: 3.5811 - acc: 0.2190 - val_loss: 3.2534 - val_acc: 0.2767\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.29187\n",
      "Epoch 38/50\n",
      "390/390 [==============================] - 583s 1s/step - loss: 3.4909 - acc: 0.2347 - val_loss: 3.1679 - val_acc: 0.2872\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.29187\n",
      "Epoch 39/50\n",
      "390/390 [==============================] - 586s 2s/step - loss: 3.3974 - acc: 0.2495 - val_loss: 3.1414 - val_acc: 0.3029\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.29187 to 0.30285, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n",
      "Epoch 40/50\n",
      "390/390 [==============================] - 583s 1s/step - loss: 3.3138 - acc: 0.2645 - val_loss: 3.0468 - val_acc: 0.3211\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.30285 to 0.32112, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n",
      "Epoch 41/50\n",
      "390/390 [==============================] - 586s 2s/step - loss: 3.2762 - acc: 0.2701 - val_loss: 3.1984 - val_acc: 0.2976\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.32112\n",
      "Epoch 42/50\n",
      "390/390 [==============================] - 587s 2s/step - loss: 3.3459 - acc: 0.2571 - val_loss: 3.3628 - val_acc: 0.2868\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.32112\n",
      "Epoch 43/50\n",
      "390/390 [==============================] - 586s 2s/step - loss: 3.4146 - acc: 0.2460 - val_loss: 3.5292 - val_acc: 0.2600\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.32112\n",
      "Epoch 44/50\n",
      "390/390 [==============================] - 583s 1s/step - loss: 3.4794 - acc: 0.2367 - val_loss: 3.6939 - val_acc: 0.2337\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.32112\n",
      "Epoch 45/50\n",
      "390/390 [==============================] - 584s 1s/step - loss: 3.5250 - acc: 0.2292 - val_loss: 3.4025 - val_acc: 0.2451\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.32112\n",
      "Epoch 46/50\n",
      "390/390 [==============================] - 583s 1s/step - loss: 3.5354 - acc: 0.2278 - val_loss: 3.5728 - val_acc: 0.2369\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.32112\n",
      "Epoch 47/50\n",
      "390/390 [==============================] - 587s 2s/step - loss: 3.4504 - acc: 0.2422 - val_loss: 3.2546 - val_acc: 0.2777\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.32112\n",
      "Epoch 48/50\n",
      "390/390 [==============================] - 588s 2s/step - loss: 3.3727 - acc: 0.2560 - val_loss: 3.2854 - val_acc: 0.2981\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.32112\n",
      "Epoch 49/50\n",
      "390/390 [==============================] - 591s 2s/step - loss: 3.2849 - acc: 0.2696 - val_loss: 3.0349 - val_acc: 0.3253\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.32112 to 0.32533, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n",
      "Epoch 50/50\n",
      "390/390 [==============================] - 585s 1s/step - loss: 3.1873 - acc: 0.2861 - val_loss: 2.9532 - val_acc: 0.3329\n",
      "\n",
      "Epoch 00050: val_acc improved from 0.32533 to 0.33292, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5ba0d06ef0>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=num_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=num_validation_samples // batch_size,\n",
    "    callbacks = callback_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "id": "6gwBPXfRxL_6",
    "outputId": "f6ff949b-db9c-49f9-b5df-a5d414cdf502"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f473ca0b459c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tiny_aug_e50.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save('tiny_aug_e50.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8VyQXmtrxZPy"
   },
   "outputs": [],
   "source": [
    "!cp /content/tiny_aug_e50.hdf5 '/content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_aug_e50.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0nNk8k1IcJk4"
   },
   "source": [
    "### Run for another 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s1W_KUJacMQd"
   },
   "outputs": [],
   "source": [
    "!cp '/content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_aug_e50.hdf5'  /content/tiny_aug_e50.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lWOcsil6dGZi"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "EwFdxA3_dLjT",
    "outputId": "fb75dc42-8d4f-42bc-c914-3c10046266d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('tiny_aug_e50.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "rtlyzU8ZdRvo",
    "outputId": "11be7d20-fb15-4a25-ab30-edcb7e7ef4e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 images belonging to 200 classes.\n",
      "dict_keys(['n01443537', 'n01629819', 'n01641577', 'n01644900', 'n01698640', 'n01742172', 'n01768244', 'n01770393', 'n01774384', 'n01774750', 'n01784675', 'n01855672', 'n01882714', 'n01910747', 'n01917289', 'n01944390', 'n01945685', 'n01950731', 'n01983481', 'n01984695', 'n02002724', 'n02056570', 'n02058221', 'n02074367', 'n02085620', 'n02094433', 'n02099601', 'n02099712', 'n02106662', 'n02113799', 'n02123045', 'n02123394', 'n02124075', 'n02125311', 'n02129165', 'n02132136', 'n02165456', 'n02190166', 'n02206856', 'n02226429', 'n02231487', 'n02233338', 'n02236044', 'n02268443', 'n02279972', 'n02281406', 'n02321529', 'n02364673', 'n02395406', 'n02403003', 'n02410509', 'n02415577', 'n02423022', 'n02437312', 'n02480495', 'n02481823', 'n02486410', 'n02504458', 'n02509815', 'n02666196', 'n02669723', 'n02699494', 'n02730930', 'n02769748', 'n02788148', 'n02791270', 'n02793495', 'n02795169', 'n02802426', 'n02808440', 'n02814533', 'n02814860', 'n02815834', 'n02823428', 'n02837789', 'n02841315', 'n02843684', 'n02883205', 'n02892201', 'n02906734', 'n02909870', 'n02917067', 'n02927161', 'n02948072', 'n02950826', 'n02963159', 'n02977058', 'n02988304', 'n02999410', 'n03014705', 'n03026506', 'n03042490', 'n03085013', 'n03089624', 'n03100240', 'n03126707', 'n03160309', 'n03179701', 'n03201208', 'n03250847', 'n03255030', 'n03355925', 'n03388043', 'n03393912', 'n03400231', 'n03404251', 'n03424325', 'n03444034', 'n03447447', 'n03544143', 'n03584254', 'n03599486', 'n03617480', 'n03637318', 'n03649909', 'n03662601', 'n03670208', 'n03706229', 'n03733131', 'n03763968', 'n03770439', 'n03796401', 'n03804744', 'n03814639', 'n03837869', 'n03838899', 'n03854065', 'n03891332', 'n03902125', 'n03930313', 'n03937543', 'n03970156', 'n03976657', 'n03977966', 'n03980874', 'n03983396', 'n03992509', 'n04008634', 'n04023962', 'n04067472', 'n04070727', 'n04074963', 'n04099969', 'n04118538', 'n04133789', 'n04146614', 'n04149813', 'n04179913', 'n04251144', 'n04254777', 'n04259630', 'n04265275', 'n04275548', 'n04285008', 'n04311004', 'n04328186', 'n04356056', 'n04366367', 'n04371430', 'n04376876', 'n04398044', 'n04399382', 'n04417672', 'n04456115', 'n04465501', 'n04486054', 'n04487081', 'n04501370', 'n04507155', 'n04532106', 'n04532670', 'n04540053', 'n04560804', 'n04562935', 'n04596742', 'n04597913', 'n06596364', 'n07579787', 'n07583066', 'n07614500', 'n07615774', 'n07695742', 'n07711569', 'n07715103', 'n07720875', 'n07734744', 'n07747607', 'n07749582', 'n07753592', 'n07768694', 'n07871810', 'n07873807', 'n07875152', 'n07920052', 'n09193705', 'n09246464', 'n09256479', 'n09332890', 'n09428293', 'n12267677'])\n",
      "dict_values([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199])\n",
      "Found 10000 images belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "## Use imgaug augmentations.\n",
    "\n",
    "# instead of applying the transformations sequentially, pick one and augment.\n",
    "#img_aug = iaa.Sequential([\n",
    "    \n",
    "img_aug = iaa.OneOf([\n",
    "    iaa.GaussianBlur(sigma=(0.0, 3.0)),    # blur the images\n",
    "    iaa.Fliplr(0.5),                       # horizontally flip 50% of the images\n",
    "    iaa.Crop(px=(0, 16)),                  # crop images from each side by 0 to 16px (randomly chosen)\n",
    "    iaa.ContrastNormalization((0.5, 1.5)), # normalize the contrast\n",
    "    iaa.CropAndPad(percent=(-0.25, 0.25)), # crop and pad with black \n",
    "    iaa.Affine(scale=(0.5, 1.5)),          # zoom in and zoom out 50 to 150%\n",
    "    iaa.Affine(translate_px={\"x\": (-20, 20), \"y\": (-20, 20)}), # translate x & y 20 pixels independently\n",
    "    iaa.Affine(rotate=(-18, 18)),          # rotate\n",
    "    iaa.Affine(shear=(-15, 15)),           # shear\n",
    "    iaa.Sharpen(alpha=(0.0, 1.0), lightness=(0.75, 2.0)) # sharpen the image\n",
    "])\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=img_aug.augment_image)\n",
    "\n",
    "## train generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                    train_data_dir,\n",
    "                    target_size=(img_width, img_height),\n",
    "                    batch_size=batch_size,\n",
    "                    class_mode='categorical')\n",
    "\n",
    "label_dict = train_generator.class_indices\n",
    "\n",
    "print(label_dict.keys())\n",
    "print(label_dict.values())\n",
    "\n",
    "## validation generator\n",
    "#validation_datagen = ImageDataGenerator(preprocessing_function=mean_subtraction)\n",
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3454
    },
    "colab_type": "code",
    "id": "Hl_gWB9zeibd",
    "outputId": "0c72b752-c29b-41f0-8b82-d8b25ba674b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "390/390 [==============================] - 348s 893ms/step - loss: 2.5408 - acc: 0.4058 - val_loss: 2.4698 - val_acc: 0.4139\n",
      "\n",
      "Epoch 00051: val_acc improved from -inf to 0.41390, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n",
      "Epoch 52/100\n",
      "390/390 [==============================] - 333s 855ms/step - loss: 2.3231 - acc: 0.4436 - val_loss: 2.5589 - val_acc: 0.4005\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.41390\n",
      "Epoch 53/100\n",
      "390/390 [==============================] - 332s 851ms/step - loss: 2.2889 - acc: 0.4471 - val_loss: 2.5334 - val_acc: 0.4051\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.41390\n",
      "Epoch 54/100\n",
      "390/390 [==============================] - 332s 850ms/step - loss: 2.2776 - acc: 0.4477 - val_loss: 2.5372 - val_acc: 0.4047\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.41390\n",
      "Epoch 55/100\n",
      "390/390 [==============================] - 333s 853ms/step - loss: 2.2608 - acc: 0.4514 - val_loss: 2.8179 - val_acc: 0.3541\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.41390\n",
      "Epoch 56/100\n",
      "390/390 [==============================] - 333s 853ms/step - loss: 2.2047 - acc: 0.4622 - val_loss: 2.5996 - val_acc: 0.3916\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.41390\n",
      "Epoch 57/100\n",
      "390/390 [==============================] - 332s 851ms/step - loss: 2.0327 - acc: 0.4988 - val_loss: 2.4335 - val_acc: 0.4389\n",
      "\n",
      "Epoch 00057: val_acc improved from 0.41390 to 0.43894, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n",
      "Epoch 58/100\n",
      "390/390 [==============================] - 332s 850ms/step - loss: 1.8649 - acc: 0.5333 - val_loss: 2.3849 - val_acc: 0.4457\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.43894 to 0.44571, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n",
      "Epoch 59/100\n",
      "390/390 [==============================] - 331s 850ms/step - loss: 1.6962 - acc: 0.5728 - val_loss: 2.2728 - val_acc: 0.4751\n",
      "\n",
      "Epoch 00059: val_acc improved from 0.44571 to 0.47506, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n",
      "Epoch 60/100\n",
      "390/390 [==============================] - 331s 850ms/step - loss: 1.5109 - acc: 0.6141 - val_loss: 2.2002 - val_acc: 0.4944\n",
      "\n",
      "Epoch 00060: val_acc improved from 0.47506 to 0.49436, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n",
      "Epoch 61/100\n",
      "390/390 [==============================] - 332s 852ms/step - loss: 1.3942 - acc: 0.6431 - val_loss: 2.2612 - val_acc: 0.4838\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.49436\n",
      "Epoch 62/100\n",
      "390/390 [==============================] - 335s 860ms/step - loss: 1.4868 - acc: 0.6191 - val_loss: 2.5499 - val_acc: 0.4421\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.49436\n",
      "Epoch 63/100\n",
      "390/390 [==============================] - 334s 856ms/step - loss: 1.6128 - acc: 0.5876 - val_loss: 2.4930 - val_acc: 0.4302\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.49436\n",
      "Epoch 64/100\n",
      "390/390 [==============================] - 332s 850ms/step - loss: 1.7197 - acc: 0.5632 - val_loss: 2.5417 - val_acc: 0.4243\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.49436\n",
      "Epoch 65/100\n",
      "390/390 [==============================] - 332s 852ms/step - loss: 1.7927 - acc: 0.5455 - val_loss: 2.6367 - val_acc: 0.4013\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.49436\n",
      "Epoch 66/100\n",
      "390/390 [==============================] - 332s 850ms/step - loss: 1.8323 - acc: 0.5366 - val_loss: 2.6326 - val_acc: 0.4274\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.49436\n",
      "Epoch 67/100\n",
      "390/390 [==============================] - 333s 855ms/step - loss: 1.6840 - acc: 0.5706 - val_loss: 2.5163 - val_acc: 0.4465\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.49436\n",
      "Epoch 68/100\n",
      "390/390 [==============================] - 332s 852ms/step - loss: 1.5180 - acc: 0.6061 - val_loss: 2.5603 - val_acc: 0.4556\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.49436\n",
      "Epoch 69/100\n",
      "390/390 [==============================] - 333s 855ms/step - loss: 1.3283 - acc: 0.6533 - val_loss: 2.3199 - val_acc: 0.4940\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.49436\n",
      "Epoch 70/100\n",
      "390/390 [==============================] - 332s 851ms/step - loss: 1.1440 - acc: 0.6991 - val_loss: 2.3244 - val_acc: 0.5070\n",
      "\n",
      "Epoch 00070: val_acc improved from 0.49436 to 0.50698, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n",
      "Epoch 71/100\n",
      "390/390 [==============================] - 332s 852ms/step - loss: 0.9862 - acc: 0.7392 - val_loss: 2.4020 - val_acc: 0.4969\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.50698\n",
      "Epoch 72/100\n",
      "390/390 [==============================] - 332s 852ms/step - loss: 1.0488 - acc: 0.7233 - val_loss: 2.6128 - val_acc: 0.4805\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.50698\n",
      "Epoch 73/100\n",
      "390/390 [==============================] - 332s 851ms/step - loss: 1.1930 - acc: 0.6836 - val_loss: 2.6229 - val_acc: 0.4576\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.50698\n",
      "Epoch 74/100\n",
      "390/390 [==============================] - 332s 851ms/step - loss: 1.3415 - acc: 0.6445 - val_loss: 2.7205 - val_acc: 0.4085\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.50698\n",
      "Epoch 75/100\n",
      "390/390 [==============================] - 332s 851ms/step - loss: 1.4716 - acc: 0.6138 - val_loss: 2.6381 - val_acc: 0.4221\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.50698\n",
      "Epoch 76/100\n",
      "390/390 [==============================] - 331s 850ms/step - loss: 1.5581 - acc: 0.5928 - val_loss: 2.9443 - val_acc: 0.4111\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.50698\n",
      "Epoch 77/100\n",
      "390/390 [==============================] - 332s 851ms/step - loss: 1.4590 - acc: 0.6167 - val_loss: 2.5766 - val_acc: 0.4466\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.50698\n",
      "Epoch 78/100\n",
      "390/390 [==============================] - 332s 851ms/step - loss: 1.2813 - acc: 0.6615 - val_loss: 2.6726 - val_acc: 0.4586\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.50698\n",
      "Epoch 79/100\n",
      "390/390 [==============================] - 332s 851ms/step - loss: 1.1069 - acc: 0.7044 - val_loss: 2.5692 - val_acc: 0.4861\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.50698\n",
      "Epoch 80/100\n",
      "390/390 [==============================] - 332s 851ms/step - loss: 0.9189 - acc: 0.7538 - val_loss: 2.5804 - val_acc: 0.4875\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.50698\n",
      "Epoch 81/100\n",
      "390/390 [==============================] - 332s 851ms/step - loss: 0.7694 - acc: 0.7950 - val_loss: 2.5167 - val_acc: 0.5080\n",
      "\n",
      "Epoch 00081: val_acc improved from 0.50698 to 0.50800, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n",
      "Epoch 82/100\n",
      "390/390 [==============================] - 332s 851ms/step - loss: 0.7701 - acc: 0.7941 - val_loss: 2.6259 - val_acc: 0.4884\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.50800\n",
      "Epoch 83/100\n",
      "390/390 [==============================] - 332s 851ms/step - loss: 0.8851 - acc: 0.7608 - val_loss: 2.8777 - val_acc: 0.4618\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.50800\n",
      "Epoch 84/100\n",
      "390/390 [==============================] - 331s 850ms/step - loss: 1.0484 - acc: 0.7175 - val_loss: 2.9505 - val_acc: 0.4233\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.50800\n",
      "Epoch 85/100\n",
      "390/390 [==============================] - 333s 854ms/step - loss: 1.1974 - acc: 0.6781 - val_loss: 2.9877 - val_acc: 0.4334\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.50800\n",
      "Epoch 86/100\n",
      "390/390 [==============================] - 333s 854ms/step - loss: 1.3236 - acc: 0.6440 - val_loss: 3.0611 - val_acc: 0.3893\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.50800\n",
      "Epoch 87/100\n",
      "390/390 [==============================] - 332s 851ms/step - loss: 1.3025 - acc: 0.6516 - val_loss: 2.7390 - val_acc: 0.4365\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.50800\n",
      "Epoch 88/100\n",
      "390/390 [==============================] - 333s 854ms/step - loss: 1.1231 - acc: 0.6972 - val_loss: 2.6023 - val_acc: 0.4574\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.50800\n",
      "Epoch 89/100\n",
      "390/390 [==============================] - 332s 852ms/step - loss: 0.9538 - acc: 0.7416 - val_loss: 2.7051 - val_acc: 0.4825\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.50800\n",
      "Epoch 90/100\n",
      "390/390 [==============================] - 333s 855ms/step - loss: 0.7928 - acc: 0.7853 - val_loss: 2.7605 - val_acc: 0.4892\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.50800\n",
      "Epoch 91/100\n",
      "390/390 [==============================] - 334s 858ms/step - loss: 0.6455 - acc: 0.8260 - val_loss: 2.6649 - val_acc: 0.5080\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.50800\n",
      "Epoch 92/100\n",
      "390/390 [==============================] - 334s 855ms/step - loss: 0.6024 - acc: 0.8373 - val_loss: 2.8231 - val_acc: 0.4927\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.50800\n",
      "Epoch 93/100\n",
      "390/390 [==============================] - 333s 853ms/step - loss: 0.6877 - acc: 0.8131 - val_loss: 3.0767 - val_acc: 0.4710\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.50800\n",
      "Epoch 94/100\n",
      "390/390 [==============================] - 333s 853ms/step - loss: 0.8261 - acc: 0.7750 - val_loss: 2.9544 - val_acc: 0.4416\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.50800\n",
      "Epoch 95/100\n",
      "390/390 [==============================] - 332s 851ms/step - loss: 0.9815 - acc: 0.7324 - val_loss: 3.0562 - val_acc: 0.4090\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.50800\n",
      "Epoch 96/100\n",
      "390/390 [==============================] - 333s 854ms/step - loss: 1.1265 - acc: 0.6935 - val_loss: 2.9092 - val_acc: 0.4099\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.50800\n",
      "Epoch 97/100\n",
      "390/390 [==============================] - 331s 850ms/step - loss: 1.1701 - acc: 0.6818 - val_loss: 2.9472 - val_acc: 0.4402\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.50800\n",
      "Epoch 98/100\n",
      "390/390 [==============================] - 331s 848ms/step - loss: 1.0243 - acc: 0.7220 - val_loss: 2.8657 - val_acc: 0.4651\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.50800\n",
      "Epoch 99/100\n",
      "390/390 [==============================] - 333s 853ms/step - loss: 0.8538 - acc: 0.7669 - val_loss: 2.9694 - val_acc: 0.4729\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.50800\n",
      "Epoch 100/100\n",
      "390/390 [==============================] - 332s 851ms/step - loss: 0.6984 - acc: 0.8083 - val_loss: 2.9023 - val_acc: 0.4856\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.50800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4cdb51f9e8>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=num_train_samples // batch_size,\n",
    "    epochs=100,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=num_validation_samples // batch_size,\n",
    "    callbacks = callback_list,\n",
    "    initial_epoch=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FbSMf1EEkPlr"
   },
   "outputs": [],
   "source": [
    "model.save('imgaug_clr_e100.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1EPUz-RmkYAW"
   },
   "outputs": [],
   "source": [
    "!cp imgaug_clr_e100.hdf5 '/content/gdrive/My Drive/App/Tiny/SGD/imgaug'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ukvNjr_NpZwb"
   },
   "source": [
    "### Instead of Augment OneOf, apply Sequential and run for 25 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "21PYC1SGkgxI",
    "outputId": "e30f0c92-1c29-4991-bcd0-f705098005a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 images belonging to 200 classes.\n",
      "dict_keys(['n01443537', 'n01629819', 'n01641577', 'n01644900', 'n01698640', 'n01742172', 'n01768244', 'n01770393', 'n01774384', 'n01774750', 'n01784675', 'n01855672', 'n01882714', 'n01910747', 'n01917289', 'n01944390', 'n01945685', 'n01950731', 'n01983481', 'n01984695', 'n02002724', 'n02056570', 'n02058221', 'n02074367', 'n02085620', 'n02094433', 'n02099601', 'n02099712', 'n02106662', 'n02113799', 'n02123045', 'n02123394', 'n02124075', 'n02125311', 'n02129165', 'n02132136', 'n02165456', 'n02190166', 'n02206856', 'n02226429', 'n02231487', 'n02233338', 'n02236044', 'n02268443', 'n02279972', 'n02281406', 'n02321529', 'n02364673', 'n02395406', 'n02403003', 'n02410509', 'n02415577', 'n02423022', 'n02437312', 'n02480495', 'n02481823', 'n02486410', 'n02504458', 'n02509815', 'n02666196', 'n02669723', 'n02699494', 'n02730930', 'n02769748', 'n02788148', 'n02791270', 'n02793495', 'n02795169', 'n02802426', 'n02808440', 'n02814533', 'n02814860', 'n02815834', 'n02823428', 'n02837789', 'n02841315', 'n02843684', 'n02883205', 'n02892201', 'n02906734', 'n02909870', 'n02917067', 'n02927161', 'n02948072', 'n02950826', 'n02963159', 'n02977058', 'n02988304', 'n02999410', 'n03014705', 'n03026506', 'n03042490', 'n03085013', 'n03089624', 'n03100240', 'n03126707', 'n03160309', 'n03179701', 'n03201208', 'n03250847', 'n03255030', 'n03355925', 'n03388043', 'n03393912', 'n03400231', 'n03404251', 'n03424325', 'n03444034', 'n03447447', 'n03544143', 'n03584254', 'n03599486', 'n03617480', 'n03637318', 'n03649909', 'n03662601', 'n03670208', 'n03706229', 'n03733131', 'n03763968', 'n03770439', 'n03796401', 'n03804744', 'n03814639', 'n03837869', 'n03838899', 'n03854065', 'n03891332', 'n03902125', 'n03930313', 'n03937543', 'n03970156', 'n03976657', 'n03977966', 'n03980874', 'n03983396', 'n03992509', 'n04008634', 'n04023962', 'n04067472', 'n04070727', 'n04074963', 'n04099969', 'n04118538', 'n04133789', 'n04146614', 'n04149813', 'n04179913', 'n04251144', 'n04254777', 'n04259630', 'n04265275', 'n04275548', 'n04285008', 'n04311004', 'n04328186', 'n04356056', 'n04366367', 'n04371430', 'n04376876', 'n04398044', 'n04399382', 'n04417672', 'n04456115', 'n04465501', 'n04486054', 'n04487081', 'n04501370', 'n04507155', 'n04532106', 'n04532670', 'n04540053', 'n04560804', 'n04562935', 'n04596742', 'n04597913', 'n06596364', 'n07579787', 'n07583066', 'n07614500', 'n07615774', 'n07695742', 'n07711569', 'n07715103', 'n07720875', 'n07734744', 'n07747607', 'n07749582', 'n07753592', 'n07768694', 'n07871810', 'n07873807', 'n07875152', 'n07920052', 'n09193705', 'n09246464', 'n09256479', 'n09332890', 'n09428293', 'n12267677'])\n",
      "dict_values([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199])\n",
      "Found 10000 images belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "## Use imgaug augmentations.\n",
    "\n",
    "# instead of applying the transformations sequentially, pick one and augment.\n",
    "#img_aug = iaa.Sequential([\n",
    "    \n",
    "#img_aug = iaa.OneOf([\n",
    "img_aug = iaa.Sequential([\n",
    "    iaa.GaussianBlur(sigma=(0.0, 3.0)),    # blur the images\n",
    "    iaa.Fliplr(0.5),                       # horizontally flip 50% of the images\n",
    "    iaa.Crop(px=(0, 16)),                  # crop images from each side by 0 to 16px (randomly chosen)\n",
    "    iaa.ContrastNormalization((0.5, 1.5)), # normalize the contrast\n",
    "    iaa.CropAndPad(percent=(-0.25, 0.25)), # crop and pad with black \n",
    "    iaa.Affine(scale=(0.5, 1.5)),          # zoom in and zoom out 50 to 150%\n",
    "    iaa.Affine(translate_px={\"x\": (-20, 20), \"y\": (-20, 20)}), # translate x & y 20 pixels independently\n",
    "    iaa.Affine(rotate=(-18, 18)),          # rotate\n",
    "    iaa.Affine(shear=(-15, 15)),           # shear\n",
    "    iaa.Sharpen(alpha=(0.0, 1.0), lightness=(0.75, 2.0)) # sharpen the image\n",
    "])\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=img_aug.augment_image)\n",
    "\n",
    "## train generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                    train_data_dir,\n",
    "                    target_size=(img_width, img_height),\n",
    "                    batch_size=batch_size,\n",
    "                    class_mode='categorical')\n",
    "\n",
    "label_dict = train_generator.class_indices\n",
    "\n",
    "print(label_dict.keys())\n",
    "print(label_dict.values())\n",
    "\n",
    "## validation generator\n",
    "#validation_datagen = ImageDataGenerator(preprocessing_function=mean_subtraction)\n",
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1986
    },
    "colab_type": "code",
    "id": "IFMSxVA6pPQK",
    "outputId": "721c137e-8680-4c83-990a-0f44f2dfaba3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 594s 2s/step - loss: 3.6614 - acc: 0.2223 - val_loss: 2.6241 - val_acc: 0.4238\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.50800\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 595s 2s/step - loss: 3.3050 - acc: 0.2682 - val_loss: 2.5724 - val_acc: 0.4321\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.50800\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 576s 1s/step - loss: 3.2494 - acc: 0.2748 - val_loss: 2.6735 - val_acc: 0.4148\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.50800\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 588s 2s/step - loss: 3.2059 - acc: 0.2800 - val_loss: 2.8006 - val_acc: 0.3996\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.50800\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 580s 1s/step - loss: 3.2125 - acc: 0.2815 - val_loss: 2.8311 - val_acc: 0.3694\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.50800\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 593s 2s/step - loss: 3.2174 - acc: 0.2794 - val_loss: 2.8987 - val_acc: 0.3640\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.50800\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 585s 2s/step - loss: 3.2291 - acc: 0.2792 - val_loss: 2.9130 - val_acc: 0.3647\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.50800\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 591s 2s/step - loss: 3.1514 - acc: 0.2925 - val_loss: 2.8391 - val_acc: 0.3921\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.50800\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 598s 2s/step - loss: 3.0609 - acc: 0.3067 - val_loss: 2.7844 - val_acc: 0.4045\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.50800\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 591s 2s/step - loss: 2.9767 - acc: 0.3219 - val_loss: 2.5944 - val_acc: 0.4266\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.50800\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 588s 2s/step - loss: 2.8880 - acc: 0.3380 - val_loss: 2.5158 - val_acc: 0.4460\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.50800\n",
      "Epoch 12/25\n",
      " 27/390 [=>............................] - ETA: 8:27 - loss: 2.8080 - acc: 0.3526"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b2a01c77e979>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_validation_samples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m#initial_epoch=51\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=num_train_samples // batch_size,\n",
    "    epochs=25,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=num_validation_samples // batch_size,\n",
    "    callbacks = callback_list\n",
    "    #initial_epoch=51\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5po8KBs67-z8"
   },
   "source": [
    "### Resume Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "2AvEyJhmC8Ph",
    "outputId": "1ac91f42-b42c-4288-a835-564363b94dec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 images belonging to 200 classes.\n",
      "dict_keys(['n01443537', 'n01629819', 'n01641577', 'n01644900', 'n01698640', 'n01742172', 'n01768244', 'n01770393', 'n01774384', 'n01774750', 'n01784675', 'n01855672', 'n01882714', 'n01910747', 'n01917289', 'n01944390', 'n01945685', 'n01950731', 'n01983481', 'n01984695', 'n02002724', 'n02056570', 'n02058221', 'n02074367', 'n02085620', 'n02094433', 'n02099601', 'n02099712', 'n02106662', 'n02113799', 'n02123045', 'n02123394', 'n02124075', 'n02125311', 'n02129165', 'n02132136', 'n02165456', 'n02190166', 'n02206856', 'n02226429', 'n02231487', 'n02233338', 'n02236044', 'n02268443', 'n02279972', 'n02281406', 'n02321529', 'n02364673', 'n02395406', 'n02403003', 'n02410509', 'n02415577', 'n02423022', 'n02437312', 'n02480495', 'n02481823', 'n02486410', 'n02504458', 'n02509815', 'n02666196', 'n02669723', 'n02699494', 'n02730930', 'n02769748', 'n02788148', 'n02791270', 'n02793495', 'n02795169', 'n02802426', 'n02808440', 'n02814533', 'n02814860', 'n02815834', 'n02823428', 'n02837789', 'n02841315', 'n02843684', 'n02883205', 'n02892201', 'n02906734', 'n02909870', 'n02917067', 'n02927161', 'n02948072', 'n02950826', 'n02963159', 'n02977058', 'n02988304', 'n02999410', 'n03014705', 'n03026506', 'n03042490', 'n03085013', 'n03089624', 'n03100240', 'n03126707', 'n03160309', 'n03179701', 'n03201208', 'n03250847', 'n03255030', 'n03355925', 'n03388043', 'n03393912', 'n03400231', 'n03404251', 'n03424325', 'n03444034', 'n03447447', 'n03544143', 'n03584254', 'n03599486', 'n03617480', 'n03637318', 'n03649909', 'n03662601', 'n03670208', 'n03706229', 'n03733131', 'n03763968', 'n03770439', 'n03796401', 'n03804744', 'n03814639', 'n03837869', 'n03838899', 'n03854065', 'n03891332', 'n03902125', 'n03930313', 'n03937543', 'n03970156', 'n03976657', 'n03977966', 'n03980874', 'n03983396', 'n03992509', 'n04008634', 'n04023962', 'n04067472', 'n04070727', 'n04074963', 'n04099969', 'n04118538', 'n04133789', 'n04146614', 'n04149813', 'n04179913', 'n04251144', 'n04254777', 'n04259630', 'n04265275', 'n04275548', 'n04285008', 'n04311004', 'n04328186', 'n04356056', 'n04366367', 'n04371430', 'n04376876', 'n04398044', 'n04399382', 'n04417672', 'n04456115', 'n04465501', 'n04486054', 'n04487081', 'n04501370', 'n04507155', 'n04532106', 'n04532670', 'n04540053', 'n04560804', 'n04562935', 'n04596742', 'n04597913', 'n06596364', 'n07579787', 'n07583066', 'n07614500', 'n07615774', 'n07695742', 'n07711569', 'n07715103', 'n07720875', 'n07734744', 'n07747607', 'n07749582', 'n07753592', 'n07768694', 'n07871810', 'n07873807', 'n07875152', 'n07920052', 'n09193705', 'n09246464', 'n09256479', 'n09332890', 'n09428293', 'n12267677'])\n",
      "dict_values([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199])\n",
      "Found 10000 images belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "## Use imgaug augmentations.\n",
    "\n",
    "# instead of applying the transformations sequentially, pick one and augment.\n",
    "#img_aug = iaa.Sequential([\n",
    "    \n",
    "#img_aug = iaa.OneOf([\n",
    "#img_aug = iaa.Sequential([\n",
    "img_aug = iaa.SomeOf(2, [\n",
    "    iaa.GaussianBlur(sigma=(0.0, 3.0)),    # blur the images\n",
    "    iaa.Fliplr(0.5),                       # horizontally flip 50% of the images\n",
    "    iaa.Crop(px=(0, 16)),                  # crop images from each side by 0 to 16px (randomly chosen)\n",
    "    iaa.ContrastNormalization((0.5, 1.5)), # normalize the contrast\n",
    "    iaa.CropAndPad(percent=(-0.25, 0.25)), # crop and pad with black \n",
    "    iaa.Affine(scale=(0.5, 1.5)),          # zoom in and zoom out 50 to 150%\n",
    "    iaa.Affine(translate_px={\"x\": (-20, 20), \"y\": (-20, 20)}), # translate x & y 20 pixels independently\n",
    "    iaa.Affine(rotate=(-18, 18)),          # rotate\n",
    "    iaa.Affine(shear=(-15, 15)),           # shear\n",
    "    iaa.Sharpen(alpha=(0.0, 1.0), lightness=(0.75, 2.0)) # sharpen the image\n",
    "])\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=img_aug.augment_image)\n",
    "\n",
    "## train generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                    train_data_dir,\n",
    "                    target_size=(img_width, img_height),\n",
    "                    batch_size=batch_size,\n",
    "                    class_mode='categorical')\n",
    "\n",
    "label_dict = train_generator.class_indices\n",
    "\n",
    "print(label_dict.keys())\n",
    "print(label_dict.values())\n",
    "\n",
    "## validation generator\n",
    "#validation_datagen = ImageDataGenerator(preprocessing_function=mean_subtraction)\n",
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1006
    },
    "colab_type": "code",
    "id": "rNi482FuDOKa",
    "outputId": "abaee092-d459-4001-8747-593834fa16cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25\n",
      "390/390 [==============================] - 342s 878ms/step - loss: 1.5802 - acc: 0.5958 - val_loss: 2.2512 - val_acc: 0.4951\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.50800\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 341s 875ms/step - loss: 1.3707 - acc: 0.6385 - val_loss: 2.3611 - val_acc: 0.4912\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.50800\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 337s 865ms/step - loss: 1.3082 - acc: 0.6551 - val_loss: 2.4120 - val_acc: 0.4813\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.50800\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 337s 864ms/step - loss: 1.3178 - acc: 0.6521 - val_loss: 2.6790 - val_acc: 0.4613\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.50800\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 338s 866ms/step - loss: 1.3948 - acc: 0.6326 - val_loss: 2.6978 - val_acc: 0.4417\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.50800\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 342s 878ms/step - loss: 1.4726 - acc: 0.6147 - val_loss: 2.7055 - val_acc: 0.4518\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.50800\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 346s 887ms/step - loss: 1.3985 - acc: 0.6332 - val_loss: 2.5747 - val_acc: 0.4686\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.50800\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 340s 871ms/step - loss: 1.2672 - acc: 0.6633 - val_loss: 2.5662 - val_acc: 0.4822\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.50800\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 341s 875ms/step - loss: 1.1361 - acc: 0.6967 - val_loss: 2.6286 - val_acc: 0.4886\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.50800\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 337s 865ms/step - loss: 1.0004 - acc: 0.7318 - val_loss: 2.5708 - val_acc: 0.5048\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.50800\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 341s 875ms/step - loss: 0.9025 - acc: 0.7578 - val_loss: 2.5358 - val_acc: 0.5113\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.50800 to 0.51129, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 341s 874ms/step - loss: 0.8977 - acc: 0.7590 - val_loss: 2.6552 - val_acc: 0.4959\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.51129\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 340s 871ms/step - loss: 0.9999 - acc: 0.7317 - val_loss: 2.7271 - val_acc: 0.4805\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.51129\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 342s 877ms/step - loss: 1.1113 - acc: 0.7007 - val_loss: 2.7280 - val_acc: 0.4633\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.51129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4cbb45da58>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=num_train_samples // batch_size,\n",
    "    epochs=25,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=num_validation_samples // batch_size,\n",
    "    callbacks = callback_list,\n",
    "    initial_epoch=11\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q0gNnMQYVTcD"
   },
   "outputs": [],
   "source": [
    "model.save('imgaug_clr_e136.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AWarvIqUVYsT"
   },
   "outputs": [],
   "source": [
    "!cp imgaug_clr_e136.hdf5 '/content/gdrive/My Drive/App/Tiny/SGD/imgaug'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h5fqCB6GUai_"
   },
   "source": [
    "### Try Class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NZlbC73BuJkw"
   },
   "outputs": [],
   "source": [
    "!cp '/content/gdrive/My Drive/App/Tiny/SGD/imgaug/imgaug_clr_e136.hdf5' /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gPeXebequxOv"
   },
   "outputs": [],
   "source": [
    "!cp '/content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5' /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LQQw3e31u3rd"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('/content/tiny_custom_best_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "A2czqwMMu8CW",
    "outputId": "aeedebae-82a1-42fb-a2ca-13fd79787de9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 200 classes.\n",
      "[2.5369316147575662, 0.5115]\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=1,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "\n",
    "score=model.evaluate_generator(generator=validation_generator, steps = num_validation_samples)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P47xBLufvnOS"
   },
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NdWNusPuvkCq",
    "outputId": "abab2503-0c7a-45ab-8dc3-02358a0dde5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 239s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "# get the predictions\n",
    "pred = model.predict_generator(validation_generator, steps = num_validation_samples, verbose=1)\n",
    "\n",
    "# get the predict class\n",
    "pred_class_indices = np.argmax(pred,axis=1)\n",
    "\n",
    "# get actual labels\n",
    "actuals = validation_generator.labels\n",
    "\n",
    "cmpare = np.equal(actuals, pred_class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SJ65Ll7QU3hA"
   },
   "source": [
    "#### Get Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZFHRj85VVR-q"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def get_class_weights(actuals, pred, class_indices, alpha=1):\n",
    "  clf_rep = precision_recall_fscore_support(actuals, pred)\n",
    "  \n",
    "  # build the dictionary\n",
    "  clf_dict = {\n",
    "             \"precision\" :clf_rep[0].round(2),\n",
    "             \"recall\" : clf_rep[1].round(2),\n",
    "             \"f1-score\" : clf_rep[2].round(2),\n",
    "             \"support\" : clf_rep[3]\n",
    "            }\n",
    "  clf_df = pd.DataFrame(clf_dict, index = class_indices)\n",
    "  \n",
    "  # build the class weights\n",
    "  class_weights = dict()\n",
    "  for class_idx in class_indices:\n",
    "    \n",
    "    f1_score = clf_df['f1-score'][class_idx]\n",
    "    \n",
    "    # weight = 1 + alpha * (1 - f1-score)\n",
    "    class_weights[class_idx] = (1 + (alpha * (1 - f1_score)) ).round(2)\n",
    "      \n",
    "  #print(class_weights)\n",
    "  return(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k0i9MecfVYnB"
   },
   "outputs": [],
   "source": [
    "class_weights = get_class_weights(actuals, \n",
    "                                  pred_class_indices, \n",
    "                                  validation_generator.class_indices.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "JUopHvWtxkFf",
    "outputId": "4b3fed3c-6101-456e-fa08-916a3a82184b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([1.23, 1.29, 1.5, 1.65, 1.52, 1.71, 1.38, 1.52, 1.31, 1.6, 1.56, 1.44, 1.37, 1.36, 1.32, 1.53, 1.7, 1.38, 1.46, 1.43, 1.29, 1.23, 1.2, 1.23, 1.69, 1.33, 1.56, 1.73, 1.45, 1.72, 1.55, 1.41, 1.71, 1.6, 1.43, 1.45, 1.27, 1.5, 1.35, 1.52, 1.71, 1.53, 1.49, 1.47, 1.15, 1.22, 1.44, 1.39, 1.63, 1.55, 1.31, 1.5, 1.24, 1.39, 1.31, 1.45, 1.54, 1.37, 1.27, 1.55, 1.31, 1.53, 1.71, 1.58, 1.78, 1.67, 1.39, 1.69, 1.4, 1.64, 1.56, 1.33, 1.59, 1.55, 1.45, 1.65, 1.52, 1.76, 1.33, 1.65, 1.7, 1.22, 1.43, 1.53, 1.56, 1.6, 1.51, 1.56, 1.79, 1.61, 1.38, 1.41, 1.51, 1.49, 1.57, 1.54, 1.64, 1.44, 1.38, 1.7, 1.76, 1.33, 1.55, 1.3, 1.63, 1.68, 1.6, 1.36, 1.31, 1.45, 1.45, 1.38, 1.58, 1.52, 1.62, 1.27, 1.61, 1.45, 1.37, 1.67, 1.65, 1.49, 1.72, 1.58, 1.27, 1.66, 1.41, 1.55, 1.53, 1.5, 1.57, 1.83, 1.83, 1.35, 1.5, 1.78, 1.54, 1.69, 1.79, 1.77, 1.52, 1.6, 1.6, 1.35, 1.55, 1.21, 1.42, 1.58, 1.44, 1.44, 1.56, 1.65, 1.53, 1.43, 1.42, 1.44, 1.52, 1.49, 1.55, 1.86, 1.59, 1.45, 1.39, 1.47, 1.48, 1.28, 1.22, 1.57, 1.79, 1.57, 1.32, 1.42, 1.71, 1.33, 1.52, 1.76, 1.27, 1.55, 1.33, 1.71, 1.65, 1.43, 1.6, 1.55, 1.36, 1.38, 1.42, 1.44, 1.58, 1.33, 1.57, 1.35, 1.45, 1.27, 1.38, 1.49, 1.4, 1.69, 1.52, 1.59])"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "77JKJPu2U7AX"
   },
   "source": [
    "#### Resume Training using Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ix-t1sfFVxXL"
   },
   "outputs": [],
   "source": [
    "## define the poly decay\n",
    "## input is epoch number and returns new alpha (lr)\n",
    "def poly_decay(epoch):\n",
    "  maxEpochs = epochs\n",
    "  base_lr   = INIT_LR\n",
    "  power     = 1.0\n",
    "  \n",
    "  # compute new lr\n",
    "  new_lr = base_lr * ( 1 - (epoch / float(maxEpochs))) ** power\n",
    "  \n",
    "  # new learning rate\n",
    "  return new_lr\n",
    "  \n",
    "##### CLR #########\n",
    "## Experiment with CLR instead of poly decay\n",
    "clr = CyclicLR(base_lr=0.001, max_lr=0.1, mode='exp_range')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3uUlIwmHV2ye"
   },
   "outputs": [],
   "source": [
    "## to save the best model \n",
    "\n",
    "checkpoint = ModelCheckpoint('/content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_class_weights_best_model.hdf5', monitor='val_acc', verbose=1, save_best_only=True)\n",
    "\n",
    "##callback_list = [checkpoint, LearningRateScheduler(poly_decay)]\n",
    "\n",
    "callback_list = [checkpoint, clr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "FkYi99RIUlah",
    "outputId": "27927ed4-7626-4057-cdac-5c5f049a4a93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 images belonging to 200 classes.\n",
      "dict_keys(['n01443537', 'n01629819', 'n01641577', 'n01644900', 'n01698640', 'n01742172', 'n01768244', 'n01770393', 'n01774384', 'n01774750', 'n01784675', 'n01855672', 'n01882714', 'n01910747', 'n01917289', 'n01944390', 'n01945685', 'n01950731', 'n01983481', 'n01984695', 'n02002724', 'n02056570', 'n02058221', 'n02074367', 'n02085620', 'n02094433', 'n02099601', 'n02099712', 'n02106662', 'n02113799', 'n02123045', 'n02123394', 'n02124075', 'n02125311', 'n02129165', 'n02132136', 'n02165456', 'n02190166', 'n02206856', 'n02226429', 'n02231487', 'n02233338', 'n02236044', 'n02268443', 'n02279972', 'n02281406', 'n02321529', 'n02364673', 'n02395406', 'n02403003', 'n02410509', 'n02415577', 'n02423022', 'n02437312', 'n02480495', 'n02481823', 'n02486410', 'n02504458', 'n02509815', 'n02666196', 'n02669723', 'n02699494', 'n02730930', 'n02769748', 'n02788148', 'n02791270', 'n02793495', 'n02795169', 'n02802426', 'n02808440', 'n02814533', 'n02814860', 'n02815834', 'n02823428', 'n02837789', 'n02841315', 'n02843684', 'n02883205', 'n02892201', 'n02906734', 'n02909870', 'n02917067', 'n02927161', 'n02948072', 'n02950826', 'n02963159', 'n02977058', 'n02988304', 'n02999410', 'n03014705', 'n03026506', 'n03042490', 'n03085013', 'n03089624', 'n03100240', 'n03126707', 'n03160309', 'n03179701', 'n03201208', 'n03250847', 'n03255030', 'n03355925', 'n03388043', 'n03393912', 'n03400231', 'n03404251', 'n03424325', 'n03444034', 'n03447447', 'n03544143', 'n03584254', 'n03599486', 'n03617480', 'n03637318', 'n03649909', 'n03662601', 'n03670208', 'n03706229', 'n03733131', 'n03763968', 'n03770439', 'n03796401', 'n03804744', 'n03814639', 'n03837869', 'n03838899', 'n03854065', 'n03891332', 'n03902125', 'n03930313', 'n03937543', 'n03970156', 'n03976657', 'n03977966', 'n03980874', 'n03983396', 'n03992509', 'n04008634', 'n04023962', 'n04067472', 'n04070727', 'n04074963', 'n04099969', 'n04118538', 'n04133789', 'n04146614', 'n04149813', 'n04179913', 'n04251144', 'n04254777', 'n04259630', 'n04265275', 'n04275548', 'n04285008', 'n04311004', 'n04328186', 'n04356056', 'n04366367', 'n04371430', 'n04376876', 'n04398044', 'n04399382', 'n04417672', 'n04456115', 'n04465501', 'n04486054', 'n04487081', 'n04501370', 'n04507155', 'n04532106', 'n04532670', 'n04540053', 'n04560804', 'n04562935', 'n04596742', 'n04597913', 'n06596364', 'n07579787', 'n07583066', 'n07614500', 'n07615774', 'n07695742', 'n07711569', 'n07715103', 'n07720875', 'n07734744', 'n07747607', 'n07749582', 'n07753592', 'n07768694', 'n07871810', 'n07873807', 'n07875152', 'n07920052', 'n09193705', 'n09246464', 'n09256479', 'n09332890', 'n09428293', 'n12267677'])\n",
      "dict_values([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199])\n",
      "Found 10000 images belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# instead of applying the transformations sequentially, pick one and augment.\n",
    "#img_aug = iaa.Sequential([\n",
    "    \n",
    "#img_aug = iaa.OneOf([\n",
    "#img_aug = iaa.Sequential([\n",
    "img_aug = iaa.SomeOf(2, [\n",
    "    iaa.GaussianBlur(sigma=(0.0, 3.0)),    # blur the images\n",
    "    iaa.Fliplr(0.5),                       # horizontally flip 50% of the images\n",
    "    iaa.Crop(px=(0, 16)),                  # crop images from each side by 0 to 16px (randomly chosen)\n",
    "    iaa.ContrastNormalization((0.5, 1.5)), # normalize the contrast\n",
    "    iaa.CropAndPad(percent=(-0.25, 0.25)), # crop and pad with black \n",
    "    iaa.Affine(scale=(0.5, 1.5)),          # zoom in and zoom out 50 to 150%\n",
    "    iaa.Affine(translate_px={\"x\": (-20, 20), \"y\": (-20, 20)}), # translate x & y 20 pixels independently\n",
    "    iaa.Affine(rotate=(-18, 18)),          # rotate\n",
    "    iaa.Affine(shear=(-15, 15)),           # shear\n",
    "    iaa.Sharpen(alpha=(0.0, 1.0), lightness=(0.75, 2.0)) # sharpen the image\n",
    "])\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=img_aug.augment_image)\n",
    "\n",
    "## train generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                    train_data_dir,\n",
    "                    target_size=(img_width, img_height),\n",
    "                    batch_size=batch_size,\n",
    "                    class_mode='categorical')\n",
    "\n",
    "label_dict = train_generator.class_indices\n",
    "\n",
    "print(label_dict.keys())\n",
    "print(label_dict.values())\n",
    "\n",
    "## validation generator\n",
    "#validation_datagen = ImageDataGenerator(preprocessing_function=mean_subtraction)\n",
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1754
    },
    "colab_type": "code",
    "id": "byF5Ws9fVd7O",
    "outputId": "97a18af4-e465-4aed-f3ad-569de9dafaca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "390/390 [==============================] - 345s 886ms/step - loss: 1.8887 - acc: 0.6729 - val_loss: 2.8290 - val_acc: 0.4472\n",
      "\n",
      "Epoch 00026: val_acc improved from -inf to 0.44725, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_class_weights_best_model.hdf5\n",
      "Epoch 27/50\n",
      "390/390 [==============================] - 340s 873ms/step - loss: 2.2284 - acc: 0.6176 - val_loss: 2.9630 - val_acc: 0.4186\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.44725\n",
      "Epoch 28/50\n",
      "390/390 [==============================] - 340s 872ms/step - loss: 2.4635 - acc: 0.5835 - val_loss: 3.0578 - val_acc: 0.3903\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.44725\n",
      "Epoch 29/50\n",
      "390/390 [==============================] - 340s 872ms/step - loss: 2.5190 - acc: 0.5745 - val_loss: 2.7509 - val_acc: 0.4370\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.44725\n",
      "Epoch 30/50\n",
      "390/390 [==============================] - 339s 870ms/step - loss: 2.2513 - acc: 0.6177 - val_loss: 2.7547 - val_acc: 0.4506\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.44725 to 0.45064, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_class_weights_best_model.hdf5\n",
      "Epoch 31/50\n",
      "390/390 [==============================] - 339s 870ms/step - loss: 1.9991 - acc: 0.6567 - val_loss: 2.7694 - val_acc: 0.4677\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.45064 to 0.46767, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_class_weights_best_model.hdf5\n",
      "Epoch 32/50\n",
      "390/390 [==============================] - 339s 870ms/step - loss: 1.7300 - acc: 0.6999 - val_loss: 2.6050 - val_acc: 0.4935\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.46767 to 0.49353, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_class_weights_best_model.hdf5\n",
      "Epoch 33/50\n",
      "390/390 [==============================] - 340s 871ms/step - loss: 1.4961 - acc: 0.7401 - val_loss: 2.5975 - val_acc: 0.5115\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.49353 to 0.51149, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_class_weights_best_model.hdf5\n",
      "Epoch 34/50\n",
      "390/390 [==============================] - 340s 872ms/step - loss: 1.3555 - acc: 0.7629 - val_loss: 2.6712 - val_acc: 0.5069\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.51149\n",
      "Epoch 35/50\n",
      "390/390 [==============================] - 340s 871ms/step - loss: 1.4867 - acc: 0.7392 - val_loss: 2.8128 - val_acc: 0.4777\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.51149\n",
      "Epoch 36/50\n",
      "390/390 [==============================] - 340s 872ms/step - loss: 1.7136 - acc: 0.7006 - val_loss: 2.9136 - val_acc: 0.4505\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.51149\n",
      "Epoch 37/50\n",
      "390/390 [==============================] - 340s 872ms/step - loss: 1.9686 - acc: 0.6578 - val_loss: 2.9141 - val_acc: 0.4507\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.51149\n",
      "Epoch 38/50\n",
      "390/390 [==============================] - 341s 873ms/step - loss: 2.2070 - acc: 0.6208 - val_loss: 3.2083 - val_acc: 0.4110\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.51149\n",
      "Epoch 39/50\n",
      "390/390 [==============================] - 343s 880ms/step - loss: 2.3575 - acc: 0.5979 - val_loss: 2.8859 - val_acc: 0.4173\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.51149\n",
      "Epoch 40/50\n",
      "390/390 [==============================] - 344s 883ms/step - loss: 2.1655 - acc: 0.6271 - val_loss: 2.8660 - val_acc: 0.4610\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.51149\n",
      "Epoch 41/50\n",
      "390/390 [==============================] - 345s 884ms/step - loss: 1.9035 - acc: 0.6701 - val_loss: 2.7858 - val_acc: 0.4759\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.51149\n",
      "Epoch 42/50\n",
      "390/390 [==============================] - 345s 885ms/step - loss: 1.6689 - acc: 0.7085 - val_loss: 2.7138 - val_acc: 0.4954\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.51149\n",
      "Epoch 43/50\n",
      "390/390 [==============================] - 345s 885ms/step - loss: 1.4213 - acc: 0.7508 - val_loss: 2.6579 - val_acc: 0.5074\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.51149\n",
      "Epoch 44/50\n",
      "390/390 [==============================] - 345s 884ms/step - loss: 1.2505 - acc: 0.7792 - val_loss: 2.7097 - val_acc: 0.5109\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.51149\n",
      "Epoch 45/50\n",
      "390/390 [==============================] - 345s 884ms/step - loss: 1.3134 - acc: 0.7683 - val_loss: 2.9196 - val_acc: 0.4912\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.51149\n",
      "Epoch 46/50\n",
      "390/390 [==============================] - 343s 881ms/step - loss: 1.5150 - acc: 0.7342 - val_loss: 2.9377 - val_acc: 0.4673\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.51149\n",
      "Epoch 47/50\n",
      "390/390 [==============================] - 343s 880ms/step - loss: 1.7524 - acc: 0.6932 - val_loss: 3.0277 - val_acc: 0.4387\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.51149\n",
      "Epoch 48/50\n",
      "390/390 [==============================] - 344s 882ms/step - loss: 2.0092 - acc: 0.6523 - val_loss: 2.9981 - val_acc: 0.4321\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.51149\n",
      "Epoch 49/50\n",
      "390/390 [==============================] - 345s 886ms/step - loss: 2.2025 - acc: 0.6207 - val_loss: 2.9586 - val_acc: 0.4187\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.51149\n",
      "Epoch 50/50\n",
      "390/390 [==============================] - 345s 884ms/step - loss: 2.0749 - acc: 0.6397 - val_loss: 2.8221 - val_acc: 0.4485\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.51149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efce4d07358>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=num_train_samples // batch_size,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=num_validation_samples // batch_size,\n",
    "    callbacks = callback_list,\n",
    "    initial_epoch=25,\n",
    "    class_weight = class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LrZ3JYWwytiJ"
   },
   "source": [
    "#### Give more weightage to failing classes (Make alpha as 2 or 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_fOgoqoE0jsC"
   },
   "outputs": [],
   "source": [
    "!cp '/content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_class_weights_best_model.hdf5' /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "rU1Dthg50l8Y",
    "outputId": "ed562375-c3a3-492f-9572-c686aa58c1a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('/content/tiny_class_weights_best_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "j7FlmLHeysM0",
    "outputId": "a8c19428-5b07-4054-d6bd-39ea510d1d16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 200 classes.\n",
      "10000/10000 [==============================] - 236s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5122"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=1,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "# get the predictions\n",
    "pred = model.predict_generator(validation_generator, steps = num_validation_samples, verbose=1)\n",
    "\n",
    "# get the predict class\n",
    "pred_class_indices = np.argmax(pred,axis=1)\n",
    "\n",
    "# get actual labels\n",
    "actuals = validation_generator.labels\n",
    "\n",
    "cmpare = np.equal(actuals, pred_class_indices)\n",
    "\n",
    "sum(cmpare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wjC5wqc6y_a-"
   },
   "source": [
    "#### Train for few more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MizOqxHOzTW_"
   },
   "outputs": [],
   "source": [
    "class_weights = get_class_weights(actuals, \n",
    "                                  pred_class_indices, \n",
    "                                  validation_generator.class_indices.values(),\n",
    "                                  alpha = 3) ## give more weightage to failing classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "nMnRVN9XhhO6",
    "outputId": "e9e34b38-1f68-460f-b785-53ef2b5e6ee2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([1.78, 1.78, 2.38, 2.92, 2.47, 3.25, 1.99, 2.59, 1.72, 2.56, 2.47, 2.32, 2.05, 1.72, 1.84, 2.56, 3.1, 2.23, 2.41, 2.11, 1.87, 1.57, 1.9, 1.87, 3.07, 1.96, 2.5, 3.13, 2.41, 2.95, 2.77, 2.29, 3.04, 2.38, 1.96, 2.32, 1.84, 2.29, 1.81, 2.56, 3.16, 2.47, 2.56, 2.41, 1.42, 1.6, 2.35, 2.08, 2.89, 2.77, 1.99, 2.29, 1.66, 2.02, 1.9, 1.99, 2.62, 2.14, 1.75, 2.74, 1.87, 2.5, 3.19, 2.62, 3.16, 3.16, 2.38, 2.86, 2.2, 2.95, 2.41, 2.05, 2.56, 2.65, 2.32, 2.98, 2.59, 3.07, 1.96, 3.13, 3.13, 1.66, 2.44, 2.83, 2.86, 2.71, 2.56, 2.83, 3.25, 2.71, 2.17, 2.02, 2.59, 2.53, 2.56, 2.71, 2.65, 2.5, 2.2, 2.98, 3.13, 1.99, 2.53, 1.84, 2.89, 2.98, 2.89, 1.87, 1.78, 2.11, 2.59, 2.14, 2.8, 2.62, 2.71, 1.66, 2.56, 2.35, 1.93, 2.89, 2.62, 2.29, 3.04, 2.98, 1.93, 3.25, 2.26, 2.53, 2.74, 2.35, 2.77, 3.73, 3.46, 1.87, 2.44, 3.4, 2.71, 2.8, 3.37, 3.25, 2.47, 2.8, 2.8, 1.69, 2.65, 1.6, 2.11, 2.77, 2.35, 2.29, 2.65, 2.74, 2.5, 2.11, 2.44, 2.38, 2.29, 2.47, 2.8, 3.49, 2.71, 2.59, 2.23, 2.32, 2.11, 1.81, 1.54, 2.59, 3.49, 2.65, 1.99, 2.08, 3.25, 1.84, 2.62, 3.46, 2.11, 2.74, 1.78, 3.13, 2.86, 2.35, 2.68, 2.5, 2.02, 2.05, 2.29, 2.05, 2.47, 1.93, 2.8, 1.96, 2.29, 1.81, 1.87, 2.47, 2.05, 2.95, 2.56, 2.62])"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "TQ2Q7yHG612i",
    "outputId": "f9507ccd-7ca7-4e41-e459-caa04bf3f97e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 images belonging to 200 classes.\n",
      "dict_keys(['n01443537', 'n01629819', 'n01641577', 'n01644900', 'n01698640', 'n01742172', 'n01768244', 'n01770393', 'n01774384', 'n01774750', 'n01784675', 'n01855672', 'n01882714', 'n01910747', 'n01917289', 'n01944390', 'n01945685', 'n01950731', 'n01983481', 'n01984695', 'n02002724', 'n02056570', 'n02058221', 'n02074367', 'n02085620', 'n02094433', 'n02099601', 'n02099712', 'n02106662', 'n02113799', 'n02123045', 'n02123394', 'n02124075', 'n02125311', 'n02129165', 'n02132136', 'n02165456', 'n02190166', 'n02206856', 'n02226429', 'n02231487', 'n02233338', 'n02236044', 'n02268443', 'n02279972', 'n02281406', 'n02321529', 'n02364673', 'n02395406', 'n02403003', 'n02410509', 'n02415577', 'n02423022', 'n02437312', 'n02480495', 'n02481823', 'n02486410', 'n02504458', 'n02509815', 'n02666196', 'n02669723', 'n02699494', 'n02730930', 'n02769748', 'n02788148', 'n02791270', 'n02793495', 'n02795169', 'n02802426', 'n02808440', 'n02814533', 'n02814860', 'n02815834', 'n02823428', 'n02837789', 'n02841315', 'n02843684', 'n02883205', 'n02892201', 'n02906734', 'n02909870', 'n02917067', 'n02927161', 'n02948072', 'n02950826', 'n02963159', 'n02977058', 'n02988304', 'n02999410', 'n03014705', 'n03026506', 'n03042490', 'n03085013', 'n03089624', 'n03100240', 'n03126707', 'n03160309', 'n03179701', 'n03201208', 'n03250847', 'n03255030', 'n03355925', 'n03388043', 'n03393912', 'n03400231', 'n03404251', 'n03424325', 'n03444034', 'n03447447', 'n03544143', 'n03584254', 'n03599486', 'n03617480', 'n03637318', 'n03649909', 'n03662601', 'n03670208', 'n03706229', 'n03733131', 'n03763968', 'n03770439', 'n03796401', 'n03804744', 'n03814639', 'n03837869', 'n03838899', 'n03854065', 'n03891332', 'n03902125', 'n03930313', 'n03937543', 'n03970156', 'n03976657', 'n03977966', 'n03980874', 'n03983396', 'n03992509', 'n04008634', 'n04023962', 'n04067472', 'n04070727', 'n04074963', 'n04099969', 'n04118538', 'n04133789', 'n04146614', 'n04149813', 'n04179913', 'n04251144', 'n04254777', 'n04259630', 'n04265275', 'n04275548', 'n04285008', 'n04311004', 'n04328186', 'n04356056', 'n04366367', 'n04371430', 'n04376876', 'n04398044', 'n04399382', 'n04417672', 'n04456115', 'n04465501', 'n04486054', 'n04487081', 'n04501370', 'n04507155', 'n04532106', 'n04532670', 'n04540053', 'n04560804', 'n04562935', 'n04596742', 'n04597913', 'n06596364', 'n07579787', 'n07583066', 'n07614500', 'n07615774', 'n07695742', 'n07711569', 'n07715103', 'n07720875', 'n07734744', 'n07747607', 'n07749582', 'n07753592', 'n07768694', 'n07871810', 'n07873807', 'n07875152', 'n07920052', 'n09193705', 'n09246464', 'n09256479', 'n09332890', 'n09428293', 'n12267677'])\n",
      "dict_values([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199])\n",
      "Found 10000 images belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "# instead of applying the transformations sequentially, pick one and augment.\n",
    "#img_aug = iaa.Sequential([\n",
    "    \n",
    "#img_aug = iaa.OneOf([\n",
    "#img_aug = iaa.Sequential([\n",
    "img_aug = iaa.SomeOf(2, [\n",
    "    iaa.GaussianBlur(sigma=(0.0, 3.0)),    # blur the images\n",
    "    iaa.Fliplr(0.5),                       # horizontally flip 50% of the images\n",
    "    iaa.Crop(px=(0, 16)),                  # crop images from each side by 0 to 16px (randomly chosen)\n",
    "    iaa.ContrastNormalization((0.5, 1.5)), # normalize the contrast\n",
    "    iaa.CropAndPad(percent=(-0.25, 0.25)), # crop and pad with black \n",
    "    iaa.Affine(scale=(0.5, 1.5)),          # zoom in and zoom out 50 to 150%\n",
    "    iaa.Affine(translate_px={\"x\": (-20, 20), \"y\": (-20, 20)}), # translate x & y 20 pixels independently\n",
    "    iaa.Affine(rotate=(-18, 18)),          # rotate\n",
    "    iaa.Affine(shear=(-15, 15)),           # shear\n",
    "    iaa.Sharpen(alpha=(0.0, 1.0), lightness=(0.75, 2.0)), # sharpen the image\n",
    "    \n",
    "    # Either drop randomly 1 to 10% of all pixels (i.e. set\n",
    "    # them to black) or drop them on an image with 2-5% percent\n",
    "    # of the original size, leading to large dropped\n",
    "    # rectangles.\n",
    "    iaa.OneOf([\n",
    "               iaa.Dropout((0.01, 0.1), per_channel=0.5),\n",
    "               iaa.CoarseDropout(\n",
    "                        (0.03, 0.15), size_percent=(0.02, 0.05),\n",
    "                        per_channel=0.2\n",
    "                    ),\n",
    "                ]),  \n",
    "], random_order=True)\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=img_aug.augment_image)\n",
    "\n",
    "## train generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                    train_data_dir,\n",
    "                    target_size=(img_width, img_height),\n",
    "                    batch_size=batch_size,\n",
    "                    class_mode='categorical')\n",
    "\n",
    "label_dict = train_generator.class_indices\n",
    "\n",
    "print(label_dict.keys())\n",
    "print(label_dict.values())\n",
    "\n",
    "## validation generator\n",
    "#validation_datagen = ImageDataGenerator(preprocessing_function=mean_subtraction)\n",
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FQIjlNdUiM9a"
   },
   "outputs": [],
   "source": [
    "## to save the best model \n",
    "\n",
    "checkpoint = ModelCheckpoint('/content/gdrive/My Drive/App/Tiny/SGD/imgaug/v3/tiny_class_weights_best_model.hdf5', monitor='val_acc', verbose=1, save_best_only=True)\n",
    "\n",
    "##callback_list = [checkpoint, LearningRateScheduler(poly_decay)]\n",
    "\n",
    "callback_list = [checkpoint, clr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Gf5B0rmlwib"
   },
   "source": [
    "##### Epochs 1 -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 734
    },
    "colab_type": "code",
    "id": "jDIQT7wizDmH",
    "outputId": "b42b2f40-e9a1-4d3f-fc70-2c177016ef44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "390/390 [==============================] - 352s 902ms/step - loss: 2.7367 - acc: 0.7247 - val_loss: 2.6657 - val_acc: 0.4837\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.48367, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/v3/tiny_class_weights_best_model.hdf5\n",
      "Epoch 2/10\n",
      "390/390 [==============================] - 339s 868ms/step - loss: 3.2026 - acc: 0.6697 - val_loss: 2.9777 - val_acc: 0.4369\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.48367\n",
      "Epoch 3/10\n",
      "390/390 [==============================] - 337s 864ms/step - loss: 3.8574 - acc: 0.6054 - val_loss: 3.0988 - val_acc: 0.4120\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.48367\n",
      "Epoch 4/10\n",
      "390/390 [==============================] - 337s 864ms/step - loss: 4.4355 - acc: 0.5525 - val_loss: 2.7673 - val_acc: 0.3914\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.48367\n",
      "Epoch 5/10\n",
      "390/390 [==============================] - 337s 864ms/step - loss: 4.8898 - acc: 0.5160 - val_loss: 3.1629 - val_acc: 0.3671\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.48367\n",
      "Epoch 6/10\n",
      "390/390 [==============================] - 337s 864ms/step - loss: 4.9688 - acc: 0.5067 - val_loss: 2.8261 - val_acc: 0.3989\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.48367\n",
      "Epoch 7/10\n",
      "390/390 [==============================] - 337s 865ms/step - loss: 4.4855 - acc: 0.5502 - val_loss: 2.6841 - val_acc: 0.4470\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.48367\n",
      "Epoch 8/10\n",
      "390/390 [==============================] - 337s 865ms/step - loss: 3.9122 - acc: 0.6019 - val_loss: 2.5121 - val_acc: 0.4672\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.48367\n",
      "Epoch 9/10\n",
      "390/390 [==============================] - 337s 864ms/step - loss: 3.3216 - acc: 0.6566 - val_loss: 2.6131 - val_acc: 0.4919\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.48367 to 0.49189, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/v3/tiny_class_weights_best_model.hdf5\n",
      "Epoch 10/10\n",
      "390/390 [==============================] - 337s 865ms/step - loss: 2.7685 - acc: 0.7099 - val_loss: 2.4790 - val_acc: 0.5147\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.49189 to 0.51468, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/v3/tiny_class_weights_best_model.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3829d4e3c8>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=num_train_samples // batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=num_validation_samples // batch_size,\n",
    "    callbacks = callback_list,\n",
    "    #initial_epoch=50,\n",
    "    class_weight = class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Y4hYnosuqgA"
   },
   "source": [
    "##### Epochs 11-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "id": "JJVcPWCCuvl-",
    "outputId": "bc669037-fc3e-4a3c-ee99-706e60159e97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "390/390 [==============================] - 340s 872ms/step - loss: 2.4578 - acc: 0.7422 - val_loss: 2.6218 - val_acc: 0.5069\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.51468\n",
      "Epoch 12/20\n",
      "390/390 [==============================] - 337s 865ms/step - loss: 2.7643 - acc: 0.7103 - val_loss: 2.6740 - val_acc: 0.4741\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.51468\n",
      "Epoch 13/20\n",
      "390/390 [==============================] - 337s 865ms/step - loss: 3.2474 - acc: 0.6627 - val_loss: 2.7756 - val_acc: 0.4495\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.51468\n",
      "Epoch 14/20\n",
      "390/390 [==============================] - 339s 870ms/step - loss: 3.7706 - acc: 0.6122 - val_loss: 2.8600 - val_acc: 0.4227\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.51468\n",
      "Epoch 15/20\n",
      "390/390 [==============================] - 338s 868ms/step - loss: 4.2738 - acc: 0.5672 - val_loss: 3.2305 - val_acc: 0.3631\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.51468\n",
      "Epoch 16/20\n",
      "390/390 [==============================] - 337s 864ms/step - loss: 4.6132 - acc: 0.5379 - val_loss: 2.7672 - val_acc: 0.4114\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.51468\n",
      "Epoch 17/20\n",
      "390/390 [==============================] - 337s 863ms/step - loss: 4.1988 - acc: 0.5751 - val_loss: 2.6659 - val_acc: 0.4515\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.51468\n",
      "Epoch 18/20\n",
      "390/390 [==============================] - 337s 864ms/step - loss: 3.6842 - acc: 0.6217 - val_loss: 2.5908 - val_acc: 0.4682\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.51468\n",
      "Epoch 19/20\n",
      "390/390 [==============================] - 336s 862ms/step - loss: 3.1493 - acc: 0.6707 - val_loss: 2.6018 - val_acc: 0.4908\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.51468\n",
      "Epoch 20/20\n",
      "390/390 [==============================] - 336s 863ms/step - loss: 2.6493 - acc: 0.7211 - val_loss: 2.5378 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.51468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3829d4e710>"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=num_train_samples // batch_size,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=num_validation_samples // batch_size,\n",
    "    callbacks = callback_list,\n",
    "    initial_epoch=10,\n",
    "    class_weight = class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "izjXz_7i-cNd"
   },
   "source": [
    "##### Epochs 21-35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ycsFzPdT-rgS"
   },
   "outputs": [],
   "source": [
    "##### CLR #########\n",
    "## Experiment with CLR instead of poly decay\n",
    "clr = CyclicLR(base_lr=0.001, max_lr=0.1, step_size=4000, mode='exp_range')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1074
    },
    "colab_type": "code",
    "id": "R1hLCPZn-x1p",
    "outputId": "a0830e3b-a9d3-47f5-f286-09873844e407"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/35\n",
      "390/390 [==============================] - 345s 885ms/step - loss: 2.2651 - acc: 0.7608 - val_loss: 2.5768 - val_acc: 0.5229\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.51468 to 0.52289, saving model to /content/gdrive/My Drive/App/Tiny/SGD/imgaug/v3/tiny_class_weights_best_model.hdf5\n",
      "Epoch 22/35\n",
      "390/390 [==============================] - 344s 881ms/step - loss: 2.4187 - acc: 0.7451 - val_loss: 2.7462 - val_acc: 0.4939\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.52289\n",
      "Epoch 23/35\n",
      "390/390 [==============================] - 346s 886ms/step - loss: 2.8189 - acc: 0.7039 - val_loss: 2.9392 - val_acc: 0.4552\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.52289\n",
      "Epoch 24/35\n",
      "390/390 [==============================] - 345s 884ms/step - loss: 3.3042 - acc: 0.6552 - val_loss: 3.0406 - val_acc: 0.4193\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.52289\n",
      "Epoch 25/35\n",
      "390/390 [==============================] - 344s 882ms/step - loss: 3.8268 - acc: 0.6056 - val_loss: 3.2471 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.52289\n",
      "Epoch 26/35\n",
      "390/390 [==============================] - 342s 878ms/step - loss: 4.2824 - acc: 0.5654 - val_loss: 3.0001 - val_acc: 0.4068\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.52289\n",
      "Epoch 27/35\n",
      "390/390 [==============================] - 342s 876ms/step - loss: 4.0645 - acc: 0.5865 - val_loss: 2.8948 - val_acc: 0.4241\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.52289\n",
      "Epoch 28/35\n",
      "390/390 [==============================] - 342s 876ms/step - loss: 3.5344 - acc: 0.6335 - val_loss: 2.7025 - val_acc: 0.4728\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.52289\n",
      "Epoch 29/35\n",
      "390/390 [==============================] - 340s 872ms/step - loss: 3.0375 - acc: 0.6820 - val_loss: 2.7935 - val_acc: 0.4801\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.52289\n",
      "Epoch 30/35\n",
      "390/390 [==============================] - 337s 865ms/step - loss: 2.5474 - acc: 0.7305 - val_loss: 2.5788 - val_acc: 0.5057\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.52289\n",
      "Epoch 31/35\n",
      "390/390 [==============================] - 337s 863ms/step - loss: 2.1680 - acc: 0.7706 - val_loss: 2.6025 - val_acc: 0.5184\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.52289\n",
      "Epoch 32/35\n",
      "390/390 [==============================] - 338s 866ms/step - loss: 2.1544 - acc: 0.7704 - val_loss: 2.7605 - val_acc: 0.4959\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.52289\n",
      "Epoch 33/35\n",
      "390/390 [==============================] - 337s 864ms/step - loss: 2.4773 - acc: 0.7368 - val_loss: 2.8515 - val_acc: 0.4680\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.52289\n",
      "Epoch 34/35\n",
      "390/390 [==============================] - 337s 864ms/step - loss: 2.9074 - acc: 0.6940 - val_loss: 3.0328 - val_acc: 0.4445\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.52289\n",
      "Epoch 35/35\n",
      "390/390 [==============================] - 339s 869ms/step - loss: 3.4531 - acc: 0.6405 - val_loss: 3.1382 - val_acc: 0.4425\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.52289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f38092e61d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=num_train_samples // batch_size,\n",
    "    epochs=35,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=num_validation_samples // batch_size,\n",
    "    callbacks = callback_list,\n",
    "    initial_epoch=20,\n",
    "    class_weight = class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WtJlHAq059Hk"
   },
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KSdKt1BV8HAD"
   },
   "outputs": [],
   "source": [
    "#!cp '/content/gdrive/My Drive/App/Tiny/SGD/imgaug/imgaug_clr_e136.hdf5' /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97BTWfzU8RaD"
   },
   "outputs": [],
   "source": [
    "#!cp '/content/gdrive/My Drive/App/Tiny/SGD/imgaug/tiny_custom_best_model.hdf5' /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EEslJL1sS0gz"
   },
   "outputs": [],
   "source": [
    "!cp '/content/gdrive/My Drive/App/Tiny/SGD/imgaug/v3/tiny_class_weights_best_model.hdf5' /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2jc6xk9k8Y1N"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "moNfMqqb8iXO"
   },
   "outputs": [],
   "source": [
    "model = load_model('/content/tiny_class_weights_best_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "LNe8PDkc8ofX",
    "outputId": "bad0391a-12c1-4092-b172-97db62f76269"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 200 classes.\n",
      "[2.587500740671457, 0.5224]\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=1,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "\n",
    "score=model.evaluate_generator(generator=validation_generator, steps = num_validation_samples)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r-Z9AmQB5-7e"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TBQ8Poe8_J8O"
   },
   "source": [
    "* Started with ResNet50. The Accuracy was around 40%\n",
    "* For this dataset, there is a **need to shorter the deepth of the network**.\n",
    "  Used Custom ResNet by **ignoring the last set of repetition blocks.**\n",
    "* Explored mulitple versions for ResNet and attempted to make the network as much **wide **as possible by avoiding the Out of Memory error from Colab.\n",
    "* Also, used SeparableConv2D(), which makes it less number of parameters.\n",
    "* Explored optimizer Adam and SGD.\n",
    "* Explored Cyclic LR and Poly decay.\n",
    "* The **Cyclic LR gave a boost of 2% **when compared with Poly decay with SGD.\n",
    "* Integrated library **imgaug for image augmentation**.\n",
    "* The final validation accuracy obtained is **52.24%**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pbRTt3hDbafG"
   },
   "source": [
    "## Future Direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XpJk5nUbbeP8"
   },
   "source": [
    "* Identify a **better and easy way to analyze** the results. Idea is to cut down the analysis time.\n",
    "  (HTML reporting). **Need to build a package to aid analysis if not available already?**\n",
    "* Given an image /class of images, how to find out the otuput of the different Conv layers.\n",
    "  Would that help in improving the accuray? Any **debugger for Computer Vision** out there? \n",
    "* Find out a mechanism for **LR finder**. With less experiment, identify the range for LR.\n",
    "* Identify the ways to improve the accuracy for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ZH5iPdD5-LT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "V3_Imgaug_clr_tiny.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
