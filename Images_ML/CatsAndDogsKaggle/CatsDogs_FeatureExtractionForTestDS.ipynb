{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features For CatsAndDogs Test Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective:** Extract the features for the Test dataset for CatsAndDogs dataset using ResNet50 architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ResNet50 pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ResNet50 network weights\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import ResNet50\n",
    "# load the ResNet50 network\n",
    "print('Loading ResNet50 network weights')\n",
    "model = ResNet50(weights='imagenet', include_top=False, pooling='avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Test Image Names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import random\n",
    "\n",
    "ImageDir = './datasets/test'\n",
    "\n",
    "# recursively go over the datset folder and get the file names.\n",
    "ImageList = list(pathlib.Path(ImageDir).rglob('*.jpg'))\n",
    "\n",
    "# test data, no need to shuffle.\n",
    "#random.shuffle(ImageList)\n",
    "\n",
    "print(len(ImageList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('datasets/test/1.jpg'), PosixPath('datasets/test/10.jpg'), PosixPath('datasets/test/100.jpg'), PosixPath('datasets/test/1000.jpg')]\n"
     ]
    }
   ],
   "source": [
    "print(ImageList[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Test Image ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "for imagePath in ImageList:\n",
    "    file_name = imagePath.as_posix()\n",
    "    class_label = file_name.split(os.path.sep)[-1].split('.')[0]\n",
    "    #print(file_name, ' ', class_label)\n",
    "    ids.append(int(class_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 10, 100]\n"
     ]
    }
   ],
   "source": [
    "print(ids[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Configuration Settings\n",
    "# total number of images to process\n",
    "\n",
    "# for initial testing the scripting\n",
    "#NUM_IMAGES = 25\n",
    "\n",
    "# for complete dataset, turn this ON.\n",
    "NUM_IMAGES = len(ImageList)\n",
    "\n",
    "### buffer info.\n",
    "BUFF_SIZE = 1000\n",
    "\n",
    "## batch\n",
    "BATCH_SIZE=25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSetWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = h5py.File('./output/cats_and_dogs_test_features.hdf5', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the dictionary like dataset entries\n",
    "\n",
    "# the output from the max pool layer from ResNet50\n",
    "\n",
    "features = db.create_dataset('features', (NUM_IMAGES, 2048), dtype='float')\n",
    "labels   = db.create_dataset('ID', (NUM_IMAGES,), dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the buffer for both the features and labels, so that we can flush them to disk when it is full.\n",
    "\n",
    "#create buffer dictionary\n",
    "buffer = { 'features': [], 'labels': [] }\n",
    "# index to the list - features\n",
    "feature_idx = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buffer Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write buffer utilities\n",
    "\n",
    "## add the features and labels from buffer -> db\n",
    "def flush_the_buffer():\n",
    "    global feature_idx\n",
    "    global buffer\n",
    "    global features\n",
    "    global labels\n",
    "    \n",
    "    to_idx = feature_idx + len(buffer['features'])\n",
    "    features[feature_idx:to_idx] = buffer['features']\n",
    "    labels[feature_idx:to_idx]   = buffer['labels']\n",
    "    \n",
    "    #update the feature idx\n",
    "    feature_idx = to_idx\n",
    "    \n",
    "    #reset the buffer\n",
    "    buffer = { 'features': [], 'labels': [] }\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add the features and labels to the buffer\n",
    "def add_to_buffer(feature_entries, labels):\n",
    "    global buffer\n",
    "    \n",
    "    buffer['features'].extend(feature_entries)\n",
    "    buffer['labels'].extend(labels)\n",
    "    \n",
    "    if len(buffer['features']) >= BUFF_SIZE :\n",
    "        flush_the_buffer()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## close the db\n",
    "def close_the_database():\n",
    "    global buffer\n",
    "    global db\n",
    "    \n",
    "    if len(buffer['features']) > 0:\n",
    "        flush_the_buffer()\n",
    "        \n",
    "    db.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features\n",
    "\n",
    "* Load the image and resize them to 224x224 for ResNet50\n",
    "* Preprocess the image for ResNet\n",
    "\n",
    "* Use model.predict() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## resize them to one size\n",
    "def preprocess_image(img, width, height, interpolation=cv2.INTER_AREA):\n",
    "    return( cv2.resize(img, (width, height), interpolation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go over all the images to extract the features in batches\n",
    "for i in np.arange(0, NUM_IMAGES, BATCH_SIZE):\n",
    "    #\n",
    "    # process them in batches\n",
    "    #\n",
    "    batchImageList = ImageList[i: i+BATCH_SIZE]\n",
    "    batchLabelsList = ids[i: i+BATCH_SIZE]\n",
    "    batchImages = []\n",
    "    #print(i)\n",
    "    \n",
    "    # loop over each image in the batchImage List\n",
    "    for (j, imagePath) in enumerate(batchImageList):\n",
    "        fileName = imagePath.as_posix()\n",
    "        # load the image\n",
    "        img = cv2.imread(fileName)\n",
    "        img = preprocess_image(img, 224, 224)\n",
    "        \n",
    "        # convert to array\n",
    "        img = img_to_array(img)\n",
    "        \n",
    "        ##preprocess the input for the ResNet architecture.\n",
    "        ## it needs in four dimensions, so expand\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = imagenet_utils.preprocess_input(img)\n",
    "        \n",
    "        # add image to the batch\n",
    "        batchImages.append(img)\n",
    "        \n",
    "    ## now pass the images thru ResNet50 network architecture and\n",
    "    batchImages = np.vstack(batchImages)\n",
    "    extracted_features = model.predict(batchImages, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    #print('extracted_features.shape :', extracted_features.shape)\n",
    "    ## get the extracted features for each image after the max pooling layer.\n",
    "    ## note that, the size after the max pooling layer is 2048 from the ResNet50 arch.\n",
    "    #\n",
    "    extracted_features = extracted_features.reshape((extracted_features.shape[0], 2048))\n",
    "    \n",
    "    ## add the features to the HDF5 dataset\n",
    "    add_to_buffer(extracted_features, batchLabelsList)\n",
    "    \n",
    "## close the HDF5 dataset\n",
    "close_the_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extractions for Test Dataset, Done!\n"
     ]
    }
   ],
   "source": [
    "print('Feature extractions for Test Dataset, Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
