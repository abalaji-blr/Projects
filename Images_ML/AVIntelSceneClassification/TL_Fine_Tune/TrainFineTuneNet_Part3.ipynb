{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intel Scene Classification - Fine Tune Training Part3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Part2 Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.training.Model object at 0x1136956a0>\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "## Load the trained new head model\n",
    "head_model_file = './model/train_5000.hdf5'\n",
    "model = load_model(head_model_file)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Training Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "## Get the training image file names\n",
    "####################\n",
    "from my_utils.datasets import DataSetLoader\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "DataLoader = DataSetLoader()\n",
    "training_files = DataLoader.get_training_file_names()\n",
    "training_labels = DataLoader.get_training_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binary = LabelBinarizer().fit_transform(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_binary[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Train and Validataion Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 4000 more images.\n",
    "trainX = DataLoader.load_images(training_files[5000:9000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = label_binary[5000:9000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainX) == len(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valX = DataLoader.load_images(training_files[16900:17000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valY = label_binary[16900:17000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train part2 of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "4000/4000 [==============================] - 4416s 1s/step - loss: 0.1747 - acc: 0.9387 - val_loss: 0.3092 - val_acc: 0.8900\n",
      "Epoch 2/5\n",
      "4000/4000 [==============================] - 4176s 1s/step - loss: 0.1540 - acc: 0.9467 - val_loss: 0.3133 - val_acc: 0.8900\n",
      "Epoch 3/5\n",
      "4000/4000 [==============================] - 3985s 996ms/step - loss: 0.1276 - acc: 0.9512 - val_loss: 0.3280 - val_acc: 0.9000\n",
      "Epoch 4/5\n",
      "4000/4000 [==============================] - 3987s 997ms/step - loss: 0.1073 - acc: 0.9610 - val_loss: 0.3233 - val_acc: 0.9000\n",
      "Epoch 5/5\n",
      "4000/4000 [==============================] - 3983s 996ms/step - loss: 0.0952 - acc: 0.9700 - val_loss: 0.3317 - val_acc: 0.9000\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(trainX, trainY, batch_size=25, validation_data=(valX, valY), \n",
    "          epochs=5,  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model/train_9000.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        14\n",
      "           1       0.88      0.93      0.90        15\n",
      "           2       0.94      0.68      0.79        22\n",
      "           3       0.83      1.00      0.91        15\n",
      "           4       0.90      1.00      0.95        19\n",
      "           5       1.00      0.87      0.93        15\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       100\n",
      "   macro avg       0.90      0.91      0.90       100\n",
      "weighted avg       0.91      0.90      0.90       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(valX)\n",
    "print(classification_report(valY.argmax(axis=1), preds.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14  0  0  0  0  0]\n",
      " [ 0 14  1  0  0  0]\n",
      " [ 0  2 15  3  2  0]\n",
      " [ 0  0  0 15  0  0]\n",
      " [ 0  0  0  0 19  0]\n",
      " [ 2  0  0  0  0 13]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(valY.argmax(axis=1), preds.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
