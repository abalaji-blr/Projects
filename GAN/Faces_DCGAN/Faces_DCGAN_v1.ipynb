{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Faces_DCGAN_v1.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O1KjlPIAFZF",
        "colab_type": "text"
      },
      "source": [
        "# Deep Convolution GAN (DCGAN) using FACES Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8Jrtg-7ASWd",
        "colab_type": "text"
      },
      "source": [
        "**Objective**: Implement Deep Convolutional GAN using Faces Dataset.\n",
        "\n",
        "Dataset Location: https://www.kaggle.com/gasgallo/faces-data-new\n",
        "\n",
        "Paper:  \n",
        "Radford, A., Metz, L., & Chintala, S. (2015). [Unsupervised representation learning with deep convolutional generative adversarial networks.](https://arxiv.org/pdf/1511.06434.pdf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYhQa3qGtIIL",
        "colab_type": "text"
      },
      "source": [
        "## Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S8k4C_4sKbb",
        "colab_type": "code",
        "outputId": "d0e113a6-b452-4877-e33b-3b4f5f26bfa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NgNXApnAe3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!cp '/content/drive/My Drive/App/DCGAN/faces-data-new.zip' .\n",
        "#!cp '/content/drive/My Drive/App/DCGAN/images_arr.64.npy' ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qy1uU9liDMnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sHbeTu2CysE",
        "colab_type": "text"
      },
      "source": [
        "## Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afgGka4fC0n9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_DATA_FILE = '/content/images_arr.64.npy'\n",
        "\n",
        "# image details\n",
        "img_rows = 64\n",
        "img_cols = 64\n",
        "channels = 3\n",
        "image_shape = (img_rows, img_cols, channels)\n",
        "\n",
        "## Latent Space (vectors) dimension\n",
        "latent_dim = 100\n",
        "\n",
        "# generated image resolution\n",
        "# 1 => 32 pixels, 2 = 32*2 = 64, 3=> 32*3 => 96 etc\n",
        "gen_image_res = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HztvHBMAmLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_arr = np.load(IMAGE_DATA_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxkxPH3zDR8a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b34ff35-2999-41ac-bb7a-2f0a9e72c407"
      },
      "source": [
        "images_arr.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7864, 64, 64, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikg5ttcRXGAB",
        "colab_type": "text"
      },
      "source": [
        "## Normalize the input data -1 to 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_oBdMvuXQZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = images_arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSvxjpWwXJkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rescale the images : -1 to 1 instead of 0 to 255\n",
        "\n",
        "X_train = X_train / 127.5 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOMs2MAHCqXH",
        "colab_type": "text"
      },
      "source": [
        "## Build DCGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FkujN_5Gk9N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aaf52490-b943-4078-dfdb-cf6fcff5f14a"
      },
      "source": [
        "from keras.layers import Input, Reshape, Dropout, Dense, Flatten, BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euQOvNHaGnzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "?BatchNormalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xshv7kwaGYap",
        "colab_type": "text"
      },
      "source": [
        "### Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLSh8Un6GgAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz_6NnicDWz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Discrimator\n",
        "#\n",
        "# Use Conv2D to identify image elements\n",
        "# Use Dropout to generalize better.\n",
        "# Use BatchNormalization - Normalize the activations of the prev layer at each batch.\n",
        "#     -Moemntum for moving mean and moving variance.\n",
        "# Use LeakyReLU for activation\n",
        "def build_discriminator(image_shape):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=image_shape, padding=\"same\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
        "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    input_image = Input(shape=image_shape)\n",
        "\n",
        "    validity = model(input_image)\n",
        "\n",
        "    return Model(input_image, validity)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De35WbEBHlLu",
        "colab_type": "text"
      },
      "source": [
        "## Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJ-5qlb5HkAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generator :\n",
        "#    latent vector(space) -> image generation.\n",
        "#    in our case vector of size 100 -> image of 64x64\n",
        "# \n",
        "def build_generator(latent_dim, channels):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(4*4*256,activation=\"relu\",input_dim=latent_dim))\n",
        "    model.add(Reshape((4,4,256)))\n",
        "\n",
        "    #Four layers of upsampling, convolution, batch normalization and activation.\n",
        "    # Further more blocks can be repeated for higher resolution.\n",
        "    #\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "   \n",
        "    # Output resolution, additional upsampling\n",
        "    for i in range(gen_image_res):\n",
        "      model.add(UpSampling2D())\n",
        "      model.add(Conv2D(128,kernel_size=3,padding=\"same\"))\n",
        "      model.add(BatchNormalization(momentum=0.8))\n",
        "      model.add(Activation(\"relu\"))\n",
        "\n",
        "    # Final CNN layer\n",
        "    model.add(Conv2D(channels,kernel_size=3,padding=\"same\"))\n",
        "    model.add(Activation(\"tanh\"))\n",
        "\n",
        "    input = Input(shape=(latent_dim,))\n",
        "    generated_image = model(input)\n",
        "\n",
        "    return Model(input,generated_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgrYQJAEKOCU",
        "colab_type": "text"
      },
      "source": [
        "## Build DCGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7zLhH8eKM63",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "1e8442fc-2e02-4f03-a9cd-655d7bc04cd0"
      },
      "source": [
        "optimizer = Adam(1.5e-4,0.5) # learning rate and momentum adjusted from paper\n",
        "\n",
        "# build discriminator\n",
        "discriminator = build_discriminator(image_shape)\n",
        "discriminator.compile(loss=\"binary_crossentropy\",optimizer=optimizer,metrics=[\"accuracy\"])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0802 08:35:58.232087 140720216610688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0802 08:35:58.233667 140720216610688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0802 08:35:58.240148 140720216610688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0802 08:35:58.254800 140720216610688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0802 08:35:58.263603 140720216610688 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0802 08:35:58.302356 140720216610688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0802 08:35:59.046957 140720216610688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0802 08:35:59.814570 140720216610688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0802 08:35:59.825007 140720216610688 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPpEvr75KOYS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "93705ac1-6626-44a2-8e9b-dbdab8728901"
      },
      "source": [
        "# build generator\n",
        "generator = build_generator(latent_dim,channels)\n",
        "\n",
        "# build the stacked model (combined model)\n",
        "random_input = Input(shape=(latent_dim,))\n",
        "\n",
        "generated_image = generator(random_input)\n",
        "\n",
        "# freeze the discrimator\n",
        "discriminator.trainable = False\n",
        "\n",
        "validity = discriminator(generated_image)\n",
        "\n",
        "# use functional Model API\n",
        "combined = Model(random_input,validity)\n",
        "\n",
        "combined.compile(loss=\"binary_crossentropy\",optimizer=optimizer, metrics=[\"accuracy\"])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0802 08:35:59.878432 140720216610688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSLJzf86Mv-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "7b3df5ea-9877-4fa4-dc7f-42f94ed97f7b"
      },
      "source": [
        "combined.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "model_2 (Model)              (None, 64, 64, 3)         2043011   \n",
            "_________________________________________________________________\n",
            "model_1 (Model)              (None, 1)                 1613889   \n",
            "=================================================================\n",
            "Total params: 3,656,900\n",
            "Trainable params: 2,041,475\n",
            "Non-trainable params: 1,615,425\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2xu22voNDC_",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tzvZPt9M5Ao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 10000\n",
        "batch_size = 32\n",
        "sample_interval = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVBPAI7GQ0bc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95d6b141-597a-4372-959b-2de8ed2062ca"
      },
      "source": [
        "!mkdir /content/gen_images2"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/gen_images2’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7fgcCVXQULa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sample images\n",
        "def sample_images(epoch):\n",
        "  r, c = 5, 5\n",
        "  noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
        "  gen_imgs = generator.predict(noise)\n",
        "\n",
        "  # Rescale images 0 - 1\n",
        "  gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "  fig, axs = plt.subplots(r, c)\n",
        "  cnt = 0\n",
        "  for i in range(r):\n",
        "    for j in range(c):\n",
        "      axs[i,j].imshow(gen_imgs[cnt, :,:,0])\n",
        "      axs[i,j].axis('off')\n",
        "      cnt += 1\n",
        "  fig.savefig(\"/content/gen_images2/%d.png\" % epoch)\n",
        "  plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AovIR1eHOmKM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "outputId": "36b27e7d-5a5a-4121-bb67-dec4e267efb1"
      },
      "source": [
        "# build Adversarial ground truths for discriminator and generator\n",
        "valid = np.ones((batch_size, 1))\n",
        "fake = np.zeros((batch_size, 1))\n",
        "\n",
        "# Train both the models.\n",
        "#\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  #--------------------\n",
        "  # train discriminator\n",
        "  #--------------------\n",
        "  # Select a random batch of images\n",
        "  idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "  imgs = X_train[idx]\n",
        "\n",
        "  # Generate a batch of new images, using generator\n",
        "  noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "  gen_imgs = generator.predict(noise)\n",
        "\n",
        "  # train generator using both real and fake images.\n",
        "  d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
        "  d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
        "  d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "  #-------------\n",
        "  # train generator\n",
        "  #-----------------\n",
        "  noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "\n",
        "  # Train the generator (to have the discriminator label samples as valid)\n",
        "  g_loss = combined.train_on_batch(noise, valid)\n",
        "\n",
        "  # If at save interval => save generated image samples\n",
        "  if epoch % sample_interval == 0:\n",
        "    # Plot the progress\n",
        "    print (\"Epoch %d [D loss: %f, acc.: %.2f%%] [G loss: %f, acc.: %.2f%%]\" % \n",
        "                          (epoch, d_loss[0], 100*d_loss[1], g_loss[0], 100*g_loss[1]))\n",
        "    sample_images(epoch)\n",
        "    "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 [D loss: 1.756560, acc.: 6.25%] [G loss: 0.541157, acc.: 78.12%]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 200 [D loss: 0.192398, acc.: 92.19%] [G loss: 5.316466, acc.: 0.00%]\n",
            "Epoch 400 [D loss: 0.627317, acc.: 76.56%] [G loss: 2.559813, acc.: 12.50%]\n",
            "Epoch 600 [D loss: 0.955609, acc.: 62.50%] [G loss: 1.763058, acc.: 18.75%]\n",
            "Epoch 800 [D loss: 0.859079, acc.: 60.94%] [G loss: 1.764447, acc.: 28.12%]\n",
            "Epoch 1000 [D loss: 0.848003, acc.: 57.81%] [G loss: 1.586489, acc.: 25.00%]\n",
            "Epoch 1200 [D loss: 0.778090, acc.: 56.25%] [G loss: 2.418842, acc.: 12.50%]\n",
            "Epoch 1400 [D loss: 0.453121, acc.: 82.81%] [G loss: 2.941964, acc.: 9.38%]\n",
            "Epoch 1600 [D loss: 0.532333, acc.: 75.00%] [G loss: 2.772845, acc.: 0.00%]\n",
            "Epoch 1800 [D loss: 0.437167, acc.: 79.69%] [G loss: 2.403053, acc.: 9.38%]\n",
            "Epoch 2000 [D loss: 0.405635, acc.: 84.38%] [G loss: 3.270834, acc.: 6.25%]\n",
            "Epoch 2200 [D loss: 0.552522, acc.: 71.88%] [G loss: 3.127317, acc.: 6.25%]\n",
            "Epoch 2400 [D loss: 0.383389, acc.: 79.69%] [G loss: 3.123402, acc.: 0.00%]\n",
            "Epoch 2600 [D loss: 0.525774, acc.: 75.00%] [G loss: 3.455653, acc.: 9.38%]\n",
            "Epoch 2800 [D loss: 0.355601, acc.: 84.38%] [G loss: 3.049943, acc.: 6.25%]\n",
            "Epoch 3000 [D loss: 0.480775, acc.: 68.75%] [G loss: 2.305466, acc.: 6.25%]\n",
            "Epoch 3200 [D loss: 0.293376, acc.: 85.94%] [G loss: 2.839504, acc.: 6.25%]\n",
            "Epoch 3400 [D loss: 0.263360, acc.: 90.62%] [G loss: 3.234019, acc.: 12.50%]\n",
            "Epoch 3600 [D loss: 0.249686, acc.: 89.06%] [G loss: 3.305447, acc.: 6.25%]\n",
            "Epoch 3800 [D loss: 0.602988, acc.: 70.31%] [G loss: 3.202565, acc.: 9.38%]\n",
            "Epoch 4000 [D loss: 0.224698, acc.: 92.19%] [G loss: 4.881125, acc.: 0.00%]\n",
            "Epoch 4200 [D loss: 0.339649, acc.: 85.94%] [G loss: 4.427938, acc.: 3.12%]\n",
            "Epoch 4400 [D loss: 0.339114, acc.: 85.94%] [G loss: 3.856655, acc.: 3.12%]\n",
            "Epoch 4600 [D loss: 0.298023, acc.: 85.94%] [G loss: 2.648455, acc.: 6.25%]\n",
            "Epoch 4800 [D loss: 0.364276, acc.: 84.38%] [G loss: 3.151049, acc.: 0.00%]\n",
            "Epoch 5000 [D loss: 0.785598, acc.: 64.06%] [G loss: 2.908012, acc.: 6.25%]\n",
            "Epoch 5200 [D loss: 0.433182, acc.: 79.69%] [G loss: 3.409920, acc.: 3.12%]\n",
            "Epoch 5400 [D loss: 0.563135, acc.: 75.00%] [G loss: 3.715900, acc.: 0.00%]\n",
            "Epoch 5600 [D loss: 0.214252, acc.: 92.19%] [G loss: 3.779187, acc.: 3.12%]\n",
            "Epoch 5800 [D loss: 0.719933, acc.: 60.94%] [G loss: 3.200023, acc.: 6.25%]\n",
            "Epoch 6000 [D loss: 0.223229, acc.: 90.62%] [G loss: 3.029028, acc.: 6.25%]\n",
            "Epoch 6200 [D loss: 0.333340, acc.: 87.50%] [G loss: 3.961807, acc.: 0.00%]\n",
            "Epoch 6400 [D loss: 0.597897, acc.: 70.31%] [G loss: 3.957228, acc.: 3.12%]\n",
            "Epoch 6600 [D loss: 0.291117, acc.: 84.38%] [G loss: 2.965770, acc.: 12.50%]\n",
            "Epoch 6800 [D loss: 0.253597, acc.: 90.62%] [G loss: 4.138844, acc.: 3.12%]\n",
            "Epoch 7000 [D loss: 0.174580, acc.: 93.75%] [G loss: 3.447899, acc.: 9.38%]\n",
            "Epoch 7200 [D loss: 0.355968, acc.: 87.50%] [G loss: 3.314405, acc.: 12.50%]\n",
            "Epoch 7400 [D loss: 0.261648, acc.: 87.50%] [G loss: 4.273481, acc.: 0.00%]\n",
            "Epoch 7600 [D loss: 0.383014, acc.: 84.38%] [G loss: 3.250535, acc.: 6.25%]\n",
            "Epoch 7800 [D loss: 0.168743, acc.: 92.19%] [G loss: 4.221025, acc.: 9.38%]\n",
            "Epoch 8000 [D loss: 0.333696, acc.: 79.69%] [G loss: 3.590798, acc.: 0.00%]\n",
            "Epoch 8200 [D loss: 0.203316, acc.: 87.50%] [G loss: 3.654128, acc.: 6.25%]\n",
            "Epoch 8400 [D loss: 0.132121, acc.: 95.31%] [G loss: 5.183776, acc.: 0.00%]\n",
            "Epoch 8600 [D loss: 0.157502, acc.: 95.31%] [G loss: 5.190461, acc.: 0.00%]\n",
            "Epoch 8800 [D loss: 0.519677, acc.: 71.88%] [G loss: 5.503546, acc.: 3.12%]\n",
            "Epoch 9000 [D loss: 0.313362, acc.: 87.50%] [G loss: 4.076159, acc.: 9.38%]\n",
            "Epoch 9200 [D loss: 0.119947, acc.: 96.88%] [G loss: 6.077293, acc.: 0.00%]\n",
            "Epoch 9400 [D loss: 0.212672, acc.: 90.62%] [G loss: 5.186713, acc.: 3.12%]\n",
            "Epoch 9600 [D loss: 0.173661, acc.: 95.31%] [G loss: 4.789862, acc.: 3.12%]\n",
            "Epoch 9800 [D loss: 0.064171, acc.: 98.44%] [G loss: 7.356376, acc.: 0.00%]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll0G6TBORPVv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba675edb-4141-4762-b0f9-78aa15d58dd1"
      },
      "source": [
        "!ls -l /content/gen_images2 | wc -l\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xla7jeHfd8ih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp '/content/gen_images2/1000.png' '/content/drive/My Drive/App/DCGAN/gen_images'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D-cHO0DjBKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp '/content/gen_images2/4000.png' '/content/drive/My Drive/App/DCGAN/gen_images'\n",
        "!cp '/content/gen_images2/6000.png' '/content/drive/My Drive/App/DCGAN/gen_images'\n",
        "!cp '/content/gen_images2/8000.png' '/content/drive/My Drive/App/DCGAN/gen_images'\n",
        "!cp '/content/gen_images2/9000.png' '/content/drive/My Drive/App/DCGAN/gen_images'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uReLNgS1jZ57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}